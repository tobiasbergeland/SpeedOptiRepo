{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTANCE = 'LR1_1_DR1_3_VC1_V7a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V8a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V9a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V11a'\n",
    "INSTANCE = 'LR1_1_DR1_4_VC3_V12a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V12b'\n",
    "# INSTANCE = 'LR1_2_DR1_3_VC2_V6a'\n",
    "# INSTANCE = 'LR1_2_DR1_3_VC3_V8a'\n",
    "# INSTANCE = 'LR2_11_DR2_22_VC3_V6a'\n",
    "# INSTANCE = 'LR2_11_DR2_33_VC4_V11a'\n",
    "\n",
    "INSTANCE_PATH = INSTANCE+'/'+INSTANCE+'.txt'\n",
    "VESSELINFO_PATH = INSTANCE+'/vessel_data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = True\n",
    "\n",
    "FA = True\n",
    "# FA = False\n",
    "\n",
    "if FA:\n",
    "    FILEPATH = f'solutions/MIRP_RF_SPEED_OPTI_results_{INSTANCE}_45_FA.txt'\n",
    "else:\n",
    "    FILEPATH = f'solutions/MIRP_RF_SPEED_OPTI_results_{INSTANCE}_45.txt'\n",
    "\n",
    "# FILEPATH = 'solutions/MIRP_RF_SPEED_OPTI_GARBAGE.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIRP-Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRP_SOL = f'solutions/MIRP_operating_speed_results_{INSTANCE}_45.txt'\n",
    "# MIRP_SOL = 'solutions/MIRP_operating_speed_GARBAGE.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-18\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model('MIRP Route Fixed with Speed Optimization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classes in order organize the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Port:\n",
    "    def __init__(self, capacity, inventory, rate, price, berth_limit, port_fee, max_amount, min_amount, number, isLoadingPort):\n",
    "        self.capacity = capacity\n",
    "        self.inventory = inventory\n",
    "        self.rate = rate\n",
    "        self.price = price \n",
    "        self.berth_limit = berth_limit \n",
    "        self.port_fee = port_fee\n",
    "        self.max_amount = max_amount\n",
    "        self.min_amount = min_amount\n",
    "        self.number = number\n",
    "        self.isLoadingPort = isLoadingPort\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Port {self.number}'\n",
    "    \n",
    "    def __repr2__(self):\n",
    "        return f'Port {self.number}: Capacity = {self.capacity}, Inventory = {self.inventory}, Rate = {self.rate}, Price = {self.price}, Berth Limit = {self.berth_limit}, Port Fee = {self.port_fee}, Max Amount = {self.max_amount}, Min Amount = {self.min_amount}, is Loading Port = {self.isLoadingPort}'\n",
    "        \n",
    "    \n",
    "\n",
    "class Node:\n",
    "    def __init__(self, port, time):\n",
    "        self.port = port\n",
    "        self.time = time\n",
    "        self.tuple = (port.number if port else None, time)\n",
    "        self.incoming_arcs = set()\n",
    "        self.outgoing_arcs = set()\n",
    "        self.berths = port.berth_limit if port else None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.tuple)\n",
    "\n",
    "\n",
    "class Arc:\n",
    "    def __init__(self, origin_node, destination_node, distance, cost, travel_time, speed, is_waiting_arc):\n",
    "        self.origin_node = origin_node\n",
    "        self.destination_node = destination_node\n",
    "        self.tuple = (origin_node, destination_node)\n",
    "        self.distance = distance\n",
    "        self.cost = cost\n",
    "        self.travel_time = travel_time\n",
    "        self.speed = speed\n",
    "        self.is_waiting_arc = is_waiting_arc\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'{self.origin_node} -> {self.destination_node} --- Cost: {self.cost} --- Speed: {self.speed}'\n",
    "\n",
    "class Vessel:\n",
    "    def __init__(self, max_inventory, initial_inventory, max_operating_quantity, number):\n",
    "        self.max_inventory = int(max_inventory)\n",
    "        self.inventory = initial_inventory\n",
    "        self.max_operating_quantity = max_operating_quantity\n",
    "        self.number = number\n",
    "        self.arcs = set()\n",
    "        self.all_arcs_v = set()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Vessel {self.number}'\n",
    "\n",
    "    def __repr2__(self):\n",
    "        return f'Vessel {self.number}: Max Inventory = {self.max_inventory}, Inventory = {self.inventory}, Max Operating Quantity = {self.max_operating_quantity}'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the provided file\n",
    "with open(INSTANCE_PATH, 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(content):\n",
    "    metadata = {}\n",
    "    start_index = content.index(\"----- MetaData -----\") + len(\"----- MetaData -----\")\n",
    "    end_index = content.find(\"\\n\\n\", start_index) if \"\\n\\n\" in content[start_index:] else len(content)\n",
    "    metadata_section = content[start_index:end_index].strip().split(\"\\n\")\n",
    "    \n",
    "    for line in metadata_section:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def safe_convert(value, data_type):\n",
    "    try:\n",
    "        if data_type == 'int':\n",
    "            return int(value)\n",
    "        elif data_type == 'float':\n",
    "            return float(value)\n",
    "        elif data_type == 'list':\n",
    "            # Handle different list formats\n",
    "            if value.startswith('[') and value.endswith(']'):\n",
    "                # Remove brackets, split by comma and strip spaces\n",
    "                return [int(x.strip()) for x in value[1:-1].split(',')]\n",
    "            else:\n",
    "                # Split by space or other delimiters if necessary\n",
    "                return [int(x.strip()) for x in value.split()]\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_and_assign_metadata_from_content(content):\n",
    "    metadata = parse_metadata(content)\n",
    "    \n",
    "    numPeriods = safe_convert(metadata.get('numPeriods', '').split()[-1], 'int')\n",
    "    numCommodities = safe_convert(metadata.get('numCommodities'), 'int')\n",
    "    numLoadingRegions = safe_convert(metadata.get('numLoadingRegions'), 'int')\n",
    "    numDischargingRegions = safe_convert(metadata.get('numDischargingRegions'), 'int')\n",
    "    numLoadingPortsInRegion = safe_convert(metadata.get('numLoadingPortsInRegion', '[]'), 'list')\n",
    "    numDischargingPortsInRegion = safe_convert(metadata.get('numDischargingPortsInRegion', '[]'), 'list')\n",
    "    numVesselClasses = safe_convert(metadata.get('numVesselClasses'), 'int')\n",
    "    numTermVesselsInClass = safe_convert(metadata.get('numTermVesselsInClass', '[]'), 'list')\n",
    "    hoursPerPeriod = safe_convert(metadata.get('hoursPerPeriod'), 'int')\n",
    "    spotMarketPricePerUnit = safe_convert(metadata.get('spotMarketPricePerUnit'), 'float')\n",
    "    spotMarketDiscountFactor = safe_convert(metadata.get('spotMarketDiscountFactor'), 'float')\n",
    "    perPeriodRewardForFinishingEarly = safe_convert(metadata.get('perPeriodRewardForFinishingEarly', '0'), 'float')\n",
    "    attemptCost = safe_convert(metadata.get('attemptCost', '0'), 'float')\n",
    "    constantForSinglePeriodAlphaSlack = safe_convert(metadata.get('constantForSinglePeriodAlphaSlack', '0'), 'float')\n",
    "    constantForCumulativeAlphaSlack = safe_convert(metadata.get('constantForCumulativeAlphaSlack', '0'), 'float')\n",
    "    \n",
    "    return {\n",
    "        'numPeriods': numPeriods,\n",
    "        'numCommodities': numCommodities,\n",
    "        'numLoadingRegions': numLoadingRegions,\n",
    "        'numDischargingRegions': numDischargingRegions,\n",
    "        'numLoadingPortsInRegion': numLoadingPortsInRegion,\n",
    "        'numDischargingPortsInRegion': numDischargingPortsInRegion,\n",
    "        'numVesselClasses': numVesselClasses,\n",
    "        'numTermVesselsInClass': numTermVesselsInClass,\n",
    "        'hoursPerPeriod': hoursPerPeriod,\n",
    "        'spotMarketPricePerUnit': spotMarketPricePerUnit,\n",
    "        'spotMarketDiscountFactor': spotMarketDiscountFactor,\n",
    "        'perPeriodRewardForFinishingEarly': perPeriodRewardForFinishingEarly,\n",
    "        'attemptCost': attemptCost,\n",
    "        'constantForSinglePeriodAlphaSlack': constantForSinglePeriodAlphaSlack,\n",
    "        'constantForCumulativeAlphaSlack': constantForCumulativeAlphaSlack\n",
    "    }\n",
    "\n",
    "# Using the refactored function with the already-read content\n",
    "metadata_from_content = read_and_assign_metadata_from_content(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual adjustments for the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We only handle one vesseltype for now'''\n",
    "metadata_from_content['numVesselClasses'] = 1\n",
    "# Therefore we set all of the vessels to be of the same type. Type 1\n",
    "vessels_in_classes = metadata_from_content['numTermVesselsInClass']\n",
    "metadata_from_content['numTermVesselsInClass'] = [sum(vessels_in_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change the numPeriods manually.\n",
    "ORIGINAL_NUM_TIME_PERIODS = metadata_from_content['numPeriods']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vessel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VESSELINFO_PATH, 'r') as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vessel_0': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 7},\n",
       " 'Vessel_1': {'Initial Inventory': 300,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_0',\n",
       "  'First Time Available': 4},\n",
       " 'Vessel_2': {'Initial Inventory': 300,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_0',\n",
       "  'First Time Available': 8},\n",
       " 'Vessel_3': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 5},\n",
       " 'Vessel_4': {'Initial Inventory': 250,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_3',\n",
       "  'First Time Available': 5},\n",
       " 'Vessel_5': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 12},\n",
       " 'Vessel_6': {'Initial Inventory': 250,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_2',\n",
       "  'First Time Available': 1},\n",
       " 'Vessel_7': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 6},\n",
       " 'Vessel_8': {'Initial Inventory': 200,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_1',\n",
       "  'First Time Available': 0},\n",
       " 'Vessel_9': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 3},\n",
       " 'Vessel_10': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 10},\n",
       " 'Vessel_11': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 1}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to extract vessel information including first time available\n",
    "pattern = r\"name\\s+Vessel_(\\d+)\\s+.*?initialInventory\\s+(\\d+)\\s+initialPort\\s+([\\w_]+)\\s+firstTimeAvailable\\s+(\\d+)\"\n",
    "\n",
    "# Finding all matches\n",
    "vessel_info = re.findall(pattern, file_content, re.DOTALL)\n",
    "\n",
    "# Creating a dictionary to store the information\n",
    "vessel_data = {}\n",
    "for vessel in vessel_info:\n",
    "    vessel_index = int(vessel[0])\n",
    "    initial_inventory = int(vessel[1])\n",
    "    initial_port = vessel[2]\n",
    "    first_time_available = int(vessel[3])\n",
    "\n",
    "    # Storing in dictionary\n",
    "    vessel_data[f\"Vessel_{vessel_index}\"] = {\n",
    "        \"Initial Inventory\": initial_inventory,\n",
    "        \"Initial Port\": initial_port,\n",
    "        \"First Time Available\": first_time_available\n",
    "    }\n",
    "\n",
    "vessel_data  # Displaying the dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in port data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_region_table(content):\n",
    "    # Extract the region table section\n",
    "    start_index = content.index(\"----- Region Table ----\") + len(\"----- Region Table ----\")\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    region_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "    regions = {}\n",
    "    for line in region_section:\n",
    "        if \"Note:\" not in line:  # Exclude the note lines\n",
    "            attribute, *values = line.split()\n",
    "            regions[attribute] = values\n",
    "    return regions\n",
    "\n",
    "\n",
    "def parse_port_table_for_region(content, region_index):\n",
    "    # Extract the port table section for the specified region\n",
    "    search_str = f\"----- Port Table For Region {region_index} ----\"\n",
    "    start_index = content.index(search_str) + len(search_str)\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    port_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "    ports = {}\n",
    "    for line in port_section:\n",
    "        attribute, *values = line.split()\n",
    "        ports[attribute] = values\n",
    "    return ports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Region 0': {'Capacity': ['670'],\n",
       "  'Inventory': ['335'],\n",
       "  'Rate': ['134'],\n",
       "  'Price': [],\n",
       "  'BerthLimit': ['1'],\n",
       "  'PortFee': ['28'],\n",
       "  'maxAmt': ['300'],\n",
       "  'minAmt': ['100'],\n",
       "  'C2R': ['ratio', '5']},\n",
       " 'Region 1': {'Capacity': ['336', '396', '480', '336'],\n",
       "  'Inventory': ['168', '198', '240', '168'],\n",
       "  'Rate': ['-42', '-36', '-32', '-24'],\n",
       "  'Price': ['5', '5', '5', '5'],\n",
       "  'BerthLimit': ['1', '1', '1', '1'],\n",
       "  'PortFee': ['62', '59', '44', '55'],\n",
       "  'maxAmt': ['300', '300', '240', '300'],\n",
       "  'minAmt': ['95', '85', '90', '80'],\n",
       "  'C2R': ['ratio', '8', '11', '15', '14']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract region and port information\n",
    "regions_info = parse_region_table(content)\n",
    "ports_info = {f\"Region {i}\": parse_port_table_for_region(content, i) for i in range(len(regions_info['NumPorts']))}\n",
    "ports_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ports_from_info_with_loading(ports_info):\n",
    "    all_ports = {}\n",
    "    loading_regions = {}\n",
    "    discharging_regions = {}\n",
    "\n",
    "    tot_num = 1\n",
    "    \n",
    "    for region, port_attributes in ports_info.items():\n",
    "        region_ports = []\n",
    "        is_loading_region = all(int(rate) > 0 for rate in port_attributes['Rate'])\n",
    "        is_discharging_region = all(int(rate) < 0 for rate in port_attributes['Rate'])\n",
    "\n",
    "        for i in range(len(port_attributes['Capacity'])):  # Assuming 'Capacity' is always present\n",
    "            rate = int(port_attributes['Rate'][i]) if 'Rate' in port_attributes else 0\n",
    "            isLoading = 1 if rate > 0 else -1  # Loading port if rate is positive\n",
    "\n",
    "            port = Port(\n",
    "                capacity=int(port_attributes['Capacity'][i]),\n",
    "                inventory=int(port_attributes['Inventory'][i]) if 'Inventory' in port_attributes else None,\n",
    "                rate=abs(rate),\n",
    "                price=int(port_attributes['Price'][i]) if 'Price' in port_attributes and port_attributes['Price'] else None,\n",
    "                berth_limit=int(port_attributes['BerthLimit'][i]) if 'BerthLimit' in port_attributes else None,\n",
    "                port_fee=int(port_attributes['PortFee'][i]) if 'PortFee' in port_attributes else None,\n",
    "                max_amount=int(port_attributes['maxAmt'][i]) if 'maxAmt' in port_attributes else None,\n",
    "                min_amount=int(port_attributes['minAmt'][i]) if 'minAmt' in port_attributes else None,\n",
    "                number=tot_num,  # Using 1 to numports+1 as the port number\n",
    "                isLoadingPort=isLoading)  # Determine loading port based on Rate value\n",
    "            region_ports.append(port)\n",
    "            tot_num += 1\n",
    "\n",
    "        all_ports[region] = region_ports\n",
    "\n",
    "        # Assign region to correct dictionary\n",
    "        if is_loading_region:\n",
    "            loading_regions[region] = region_ports\n",
    "        elif is_discharging_region:\n",
    "            discharging_regions[region] = region_ports\n",
    "\n",
    "    return all_ports, loading_regions, discharging_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ports, loading_regions, discharging_regions = create_ports_from_info_with_loading(ports_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 1, Port 2, Port 3, Port 4, Port 5]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all ports\n",
    "ports = []\n",
    "for region, region_ports in all_ports.items():\n",
    "    ports.extend(region_ports)\n",
    "ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 1: Capacity = 670, Inventory = 335, Rate = 134, Price = None, Berth Limit = 1, Port Fee = 28, Max Amount = 300, Min Amount = 100, is Loading Port = 1\n",
      "Port 2: Capacity = 336, Inventory = 168, Rate = 42, Price = 5, Berth Limit = 1, Port Fee = 62, Max Amount = 300, Min Amount = 95, is Loading Port = -1\n",
      "Port 3: Capacity = 396, Inventory = 198, Rate = 36, Price = 5, Berth Limit = 1, Port Fee = 59, Max Amount = 300, Min Amount = 85, is Loading Port = -1\n",
      "Port 4: Capacity = 480, Inventory = 240, Rate = 32, Price = 5, Berth Limit = 1, Port Fee = 44, Max Amount = 240, Min Amount = 90, is Loading Port = -1\n",
      "Port 5: Capacity = 336, Inventory = 168, Rate = 24, Price = 5, Berth Limit = 1, Port Fee = 55, Max Amount = 300, Min Amount = 80, is Loading Port = -1\n"
     ]
    }
   ],
   "source": [
    "for port in ports:\n",
    "    print(port.__repr2__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL PARAMETERS\n",
    "\n",
    "All parameters should be set below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time periods\n",
    "NUM_TIME_PERIODS = 45\n",
    "metadata_from_content['numPeriods'] = NUM_TIME_PERIODS\n",
    "TIME_PERIOD_RANGE = list(range(1, NUM_TIME_PERIODS+1))\n",
    "\n",
    "# Number of vessels\n",
    "ORIGINAL_NUM_VESSELS = metadata_from_content['numTermVesselsInClass'][0]\n",
    "NUM_VESSELS = ORIGINAL_NUM_VESSELS\n",
    "\n",
    "# Speed interval\n",
    "MAX_SPEED = 15\n",
    "MIN_SPEED = 8\n",
    "OPERATING_SPEED = 14\n",
    "\n",
    "# Operating cost\n",
    "OPERATING_COST = 200\n",
    "\n",
    "# Waiting cost\n",
    "WAITING_COST = 50\n",
    "\n",
    "# Fuel price in USD per ton\n",
    "FUEL_PRICE = 500\n",
    "\n",
    "#Numper of ports\n",
    "NUM_PORTS = len(ports)\n",
    "\n",
    "EBS = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vessel_table(content):\n",
    "    # Extract the vessel table section\n",
    "    start_index = content.index(\"----- Vessel Table ----\") + len(\"----- Vessel Table ----\")\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    vessel_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "\n",
    "    vessels = {}\n",
    "    class_0_capacity = None\n",
    "\n",
    "    # Extract vessel attributes\n",
    "    for line in vessel_section:\n",
    "        if \"Note:\" not in line:  # Exclude the note lines\n",
    "            attribute, *values = line.split()\n",
    "            vessels[attribute] = values\n",
    "\n",
    "    # Find indices of Class 0 vessels\n",
    "    class_0_indices = [i for i, v in enumerate(vessels.get(\"Class\", [])) if v == \"0\"]\n",
    "\n",
    "    # Extract the capacity for Class 0 vessels\n",
    "    if class_0_indices:\n",
    "        class_0_capacity_index = class_0_indices[0]\n",
    "        class_0_capacity = int(vessels.get(\"Capacity\", [])[class_0_capacity_index])\n",
    "\n",
    "    return vessels, class_0_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Type': ['Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term',\n",
       "   'Term'],\n",
       "  'Class': ['0', '0', '0', '0', '1', '1', '1', '1', '2', '2', '2', '2'],\n",
       "  'Capacity': ['300',\n",
       "   '300',\n",
       "   '300',\n",
       "   '300',\n",
       "   '250',\n",
       "   '250',\n",
       "   '250',\n",
       "   '250',\n",
       "   '200',\n",
       "   '200',\n",
       "   '200',\n",
       "   '200']},\n",
       " 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the vessel dictionary and the capacity for Class 0 vessels\n",
    "vessels_info, VESSEL_CAP = parse_vessel_table(content)\n",
    "(vessels_info, VESSEL_CAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with key = vessel class and value = vessel object\n",
    "vessels = {}\n",
    "tot = 1\n",
    "for vessel_class in range(metadata_from_content['numVesselClasses']):\n",
    "    vessel_list = []\n",
    "    vessels_in_class = metadata_from_content['numTermVesselsInClass'][vessel_class]\n",
    "    for i in range(vessels_in_class):\n",
    "        if int(vessel_data['Vessel_'+str(i)]['Initial Inventory'])>0:\n",
    "            init_inventory = VESSEL_CAP\n",
    "        else:\n",
    "            init_inventory = 0\n",
    "            \n",
    "        vessel_list.append(Vessel(\n",
    "            max_inventory= VESSEL_CAP,\n",
    "            initial_inventory= init_inventory,\n",
    "            max_operating_quantity=VESSEL_CAP,\n",
    "            number=tot\n",
    "        ))\n",
    "        tot += 1\n",
    "    vessels[vessel_class] = vessel_list\n",
    "\n",
    "# We only have one vessel class. Convert the dictionary to a list\n",
    "vessels = vessels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 1,\n",
       " Vessel 2,\n",
       " Vessel 3,\n",
       " Vessel 4,\n",
       " Vessel 5,\n",
       " Vessel 6,\n",
       " Vessel 7,\n",
       " Vessel 8,\n",
       " Vessel 9,\n",
       " Vessel 10,\n",
       " Vessel 11,\n",
       " Vessel 12]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually set the number of vessels\n",
    "vessels = vessels[:NUM_VESSELS]\n",
    "vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel 1: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 2: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 3: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 4: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 5: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 6: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 7: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 8: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 9: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 10: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 11: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 12: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n"
     ]
    }
   ],
   "source": [
    "for v in vessels:\n",
    "    print(v.__repr2__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXING THE ROUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the file from MIRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vessel_routes(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "        # Find the start of the Vessel Routes section\n",
    "        start = content.find(\"Vessel Routes:\")\n",
    "        if start == -1:\n",
    "            return \"Vessel Routes section not found in the file.\"\n",
    "\n",
    "        # Extract the Vessel Routes section\n",
    "        vessel_routes_section = content[start:].split(\"\\n\", 1)[1]\n",
    "        vessel_routes_section = vessel_routes_section.split(\"\\n\\n\", 1)[0]  # Assumes there's a blank line after the section\n",
    "\n",
    "        # Process the section to create the dictionary\n",
    "        VESSEL_ROUTES = {}\n",
    "        for line in vessel_routes_section.strip().split('\\n'):\n",
    "            vessel_number, route = line.split(': ')\n",
    "            vessel_number = int(vessel_number.split(' ')[1])\n",
    "            route = eval(route)\n",
    "            VESSEL_ROUTES[vessels[vessel_number - 1]] = route\n",
    "\n",
    "        return VESSEL_ROUTES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Vessel 5: [5, 1, 5], Vessel 7: [4, 1, 4, 1], Vessel 10: [1, 4, 1, 5], Vessel 11: [1, 4, 1], Vessel 12: [1, 5]}\n"
     ]
    }
   ],
   "source": [
    "VESSEL_ROUTES = read_vessel_routes(MIRP_SOL)\n",
    "print(VESSEL_ROUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 1, Vessel 2, Vessel 3, Vessel 4, Vessel 6, Vessel 8, Vessel 9]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all vessels that are not in the solution\n",
    "vessels_to_remove = [v for v in vessels if v not in VESSEL_ROUTES]\n",
    "vessels_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the vessels that are not in the solution\n",
    "# vessels = list(VESSEL_ROUTES.keys())\n",
    "# vessels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the regular nodes\n",
    "regularNodes = []\n",
    "for t in range(1, NUM_TIME_PERIODS+1):\n",
    "    for port in ports:\n",
    "        node = Node(port=port, time=t)\n",
    "        regularNodes.append(node)\n",
    "    \n",
    "# Create fictional source and sink port\n",
    "sourcePort = Port(capacity=None, inventory=None, rate=None, price=None, berth_limit=len(vessels), port_fee=0, max_amount=None, min_amount=None, number=0, isLoadingPort=True)\n",
    "sinkPort = Port(capacity=None, inventory=None, rate=None, price=None, berth_limit=len(vessels), port_fee=0, max_amount=None, min_amount=None, number=len(ports)+1, isLoadingPort=False)\n",
    "\n",
    "# Create source and sink node\n",
    "sourceNode = Node(port=sourcePort, time=0)\n",
    "sinkNode = Node(port=sinkPort, time=NUM_TIME_PERIODS+1)\n",
    "\n",
    "NODES = [sourceNode] + regularNodes + [sinkNode]\n",
    "\n",
    "# Create a node dictionary with key = (port, time) tuple and value = node object\n",
    "NODE_DICT = {}\n",
    "for node in NODES:\n",
    "    NODE_DICT[node.tuple] = node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in arc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 7083.82, 7725.2, 7446.65, 7571.48],\n",
       " [7083.82, 0.0, 750.08, 363.99, 504.05],\n",
       " [7725.2, 750.08, 0.0, 461.81, 309.79],\n",
       " [7446.65, 363.99, 461.81, 0.0, 160.33],\n",
       " [7571.48, 504.05, 309.79, 160.33, 0.0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_full_distance_matrix(content):\n",
    "    # Extract the full distance matrix section\n",
    "    start_str = \"----- FullDistanceMatrix ----\"\n",
    "    start_index = content.index(start_str) + len(start_str)\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    matrix_section = content[start_index:end_index].strip().split(\"\\n\")[2:]  # Exclude the header lines\n",
    "    \n",
    "    # Convert the matrix section to a 2D list of distances\n",
    "    distances = []\n",
    "    for line in matrix_section:\n",
    "        try:\n",
    "            distance_row = list(map(float, line.split()[1:]))  # Excluding the leading port number\n",
    "            distances.append(distance_row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Extracting the full distance matrix from the file content\n",
    "full_distance_matrix = parse_full_distance_matrix(content)\n",
    "full_distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DISTANCE_MATRIX = full_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert full_distance_matrix from km to nautical miles\n",
    "# 1 nautical mile = 1.852 km\n",
    "def km_to_nautical_miles(km):\n",
    "    return km / 1.852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_matrix_to_nautical_miles(matrix):\n",
    "    return [[km_to_nautical_miles(distance) for distance in row] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  3824.9568034557233,\n",
       "  4171.274298056155,\n",
       "  4020.869330453563,\n",
       "  4088.2721382289415],\n",
       " [3824.9568034557233,\n",
       "  0.0,\n",
       "  405.0107991360691,\n",
       "  196.5388768898488,\n",
       "  272.1652267818574],\n",
       " [4171.274298056155,\n",
       "  405.0107991360691,\n",
       "  0.0,\n",
       "  249.35745140388767,\n",
       "  167.2732181425486],\n",
       " [4020.869330453563,\n",
       "  196.5388768898488,\n",
       "  249.35745140388767,\n",
       "  0.0,\n",
       "  86.57127429805615],\n",
       " [4088.2721382289415,\n",
       "  272.1652267818574,\n",
       "  167.2732181425486,\n",
       "  86.57127429805615,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_distance_matrix_nm = convert_matrix_to_nautical_miles(FULL_DISTANCE_MATRIX)\n",
    "full_distance_matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuel_consumption_speed_nm(speed, nautical_miles):\n",
    "    \"\"\"\n",
    "    Calculate the fuel consumption based on speed and nautical miles.\n",
    "\n",
    "    Args:\n",
    "    - speed (float): Speed of the vessel in knots.\n",
    "    - nautical miles (float): .\n",
    "\n",
    "    Returns:\n",
    "    - float: Fuel consumption in tons.\n",
    "    \"\"\"\n",
    "    return  (0.15*14 * (speed / 14) ** 3) * nautical_miles/speed\n",
    "    \n",
    "\n",
    "def calc_cost(fuel_consumption):\n",
    "    \"\"\"\n",
    "    Calculate the cost based on fuel consumption.\n",
    "\n",
    "    Args:\n",
    "    - fuel_consumption (float): Fuel consumption in tons.\n",
    "\n",
    "    Returns:\n",
    "    - float: Cost in USD.\n",
    "    \"\"\"\n",
    "    return fuel_consumption * FUEL_PRICE\n",
    "\n",
    "# Function to calculate discrete max speed based on distance and global max speed\n",
    "def calculate_minimum_timesteps_and_speed(distance_nm):\n",
    "    \"\"\"\n",
    "    Determine the minimum timesteps and speed based on distance and max speed.\n",
    "\n",
    "    Args:\n",
    "    - distance_nm (float): Distance in nautical miles.\n",
    "    - MAX_SPEED (float): Maximum speed in knots.\n",
    "    - MIN_SPEED (float): Minimum speed in knots.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Minimum timesteps and speed.\n",
    "    \"\"\"\n",
    "    hours = distance_nm / MAX_SPEED\n",
    "    minimum_timesteps = math.ceil(hours / 24)\n",
    "    speed = distance_nm / (minimum_timesteps * 24)\n",
    "    return minimum_timesteps, max(speed, MIN_SPEED)\n",
    "\n",
    "# Function to calculate discrete max speed based on distance and global max speed\n",
    "def calculate_minimum_timesteps_with_fixed_speed(distance_nm):\n",
    "    \"\"\"\n",
    "    Determine the minimum timesteps and speed based on distance and operating speed.\n",
    "\n",
    "    Args:\n",
    "    - distance_nm (float): Distance in nautical miles.\n",
    "    - operating_speed (float): Operating speed in knots.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Minimum timesteps and operating speed.\n",
    "    \"\"\"\n",
    "    hours = distance_nm / OPERATING_SPEED\n",
    "    minimum_timesteps = math.ceil(hours / 24)\n",
    "    # The speed will be operating speed no matter what, but we will round up the timesteps\n",
    "    return minimum_timesteps, OPERATING_SPEED\n",
    "    \n",
    "# Based on rounded_hours and speed calculate the next speeds\n",
    "# Creates a list with all the information needed to create the arc.\n",
    "def create_arc_info(speed, minimum_timesteps, departure, origin_port, destination_port, lowest_speed, distance_to_port, vessel, is_waiting_arc):\n",
    "    # Create a list of tuples with the speed and the time period\n",
    "    '''arc_info: (speed in knots, timesteps for sailing, time period of departure, time period of arrival, origin port, destination port, fuel_consumption)'''\n",
    "    \n",
    "    arrival_time = departure + minimum_timesteps\n",
    "    if arrival_time > NUM_TIME_PERIODS:\n",
    "        return None\n",
    "    if is_waiting_arc:\n",
    "        fuel_consumption = 0\n",
    "        arc_info = [(speed, 1, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    else:\n",
    "        fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "        arc_info = [(speed, minimum_timesteps, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    \n",
    "        timesteps = minimum_timesteps+1\n",
    "        while True:\n",
    "            \n",
    "            # Calculate the next speed\n",
    "            speed = distance_to_port / ((timesteps)*24)\n",
    "            # If the speed is lower than the lowest speed, break the loop\n",
    "            if speed < lowest_speed:\n",
    "                break\n",
    "            fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "            arrival_time = departure + timesteps\n",
    "            # Otherwise, add the speed to the list\n",
    "            arc_info.append((speed, timesteps, departure, arrival_time, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc))\n",
    "            # Increment the time period\n",
    "            timesteps += 1\n",
    "            arrival_time = departure + timesteps\n",
    "            if arrival_time > NUM_TIME_PERIODS:\n",
    "                break\n",
    "       \n",
    "    return arc_info\n",
    "\n",
    "\n",
    "# Based on rounded_hours and speed calculate the next speeds\n",
    "# Creates a list with all the information needed to create the arc.\n",
    "def create_arc_info_fixed_speed(speed, minimum_timesteps, departure, arrival_time, origin_port, destination_port, distance_to_port, vessel, is_waiting_arc):\n",
    "    # Create a list of tuples with the speed and the time period\n",
    "    '''arc_info: (speed in knots, timesteps for sailing, time period of departure, time period of arrival, origin port, destination port, fuel_consumption)'''\n",
    "    \n",
    "    if arrival_time > NUM_TIME_PERIODS:\n",
    "        return None\n",
    "    if is_waiting_arc:\n",
    "        fuel_consumption = 0\n",
    "        arc_info = [(speed, 1, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    else:\n",
    "        fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "        arc_info = [(speed, minimum_timesteps, departure, arrival_time, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "       \n",
    "    return arc_info\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to have starting positions for each vessel. \n",
    "### That way we can find the earliest time a vessel can be at each port.\n",
    "\n",
    "For now we just randomly generate distances to each of the ports, without thinking about whether it is practically possible to have these distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the information for the arcs from the source node to the ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [Port 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use vessel data to find starting positions for each vessel\n",
    "# Generate the arcs\n",
    "# For the keys in discharging_regions, change the key to index of the region starting with 0\n",
    "loading_regions_reidx = {}\n",
    "\n",
    "# Reassign keys\n",
    "for i, key in enumerate(loading_regions.keys()):\n",
    "    loading_regions_reidx[i] = loading_regions[key]\n",
    "    \n",
    "loading_regions_reidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [Port 2, Port 3, Port 4, Port 5]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the keys in discharging_regions, change the key to index of the region starting with 0\n",
    "discharging_regions_reidx = {}\n",
    "\n",
    "# Reassign keys\n",
    "for i, key in enumerate(discharging_regions.keys()):\n",
    "    discharging_regions_reidx[i] = discharging_regions[key]\n",
    "    \n",
    "discharging_regions_reidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the information for the arcs from the source node to the ports.\n",
    "- We only get one arc for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_info={}\n",
    "\n",
    "def generate_source_arc_info(sourceNode):\n",
    "    \n",
    "    source_arcs_info = []\n",
    "        \n",
    "    \n",
    "    for vessel in vessels:\n",
    "        \n",
    "        initial_port_str = vessel_data['Vessel_'+str(vessel.number-1)]['Initial Port']\n",
    "        region_index, port_index = int(initial_port_str.split('_')[1]), int(initial_port_str.split('_')[3])\n",
    "        \n",
    "        # Check whether the initial port is a loading port or a discharging port based on initial_port_str\n",
    "        if initial_port_str.startswith('Loading'):\n",
    "            region_ports = loading_regions_reidx[region_index]\n",
    "            initial_port = region_ports[int(port_index)]\n",
    "        \n",
    "        else:\n",
    "            region_ports = discharging_regions_reidx[region_index]\n",
    "            initial_port = region_ports[int(port_index)]\n",
    "                \n",
    "        first_time_available = int(vessel_data['Vessel_'+str(vessel.number-1)]['First Time Available']+1)\n",
    "        \n",
    "        start_info[vessel] = NODE_DICT[(initial_port.number, first_time_available)]\n",
    "\n",
    "        \n",
    "        # Only create one arc from the source to the corresponding port and time pair\n",
    "        source_arcs_info_for_vessel = []\n",
    "        \n",
    "        speed = 0\n",
    "        \n",
    "        arc_info = [(speed, first_time_available, 0, first_time_available, sourceNode.port.number, initial_port.number, 0, 0, vessel, False)]\n",
    "        \n",
    "        source_arcs_info_for_vessel.append(arc_info)\n",
    "        \n",
    "        source_arcs_info.append(source_arcs_info_for_vessel)\n",
    "                \n",
    "    return source_arcs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = {vessel: vessel_data['Vessel_'+str(vessel.number-1)]['First Time Available']+1 for vessel in vessels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arcs_for_node(node, vessels, all_port_numbers, source_times, full_distance_matrix_nm):\n",
    "    node_arcs = []\n",
    "    \n",
    "    for vessel in vessels:\n",
    "        if node.port.number in [0, len(ports) + 1]:\n",
    "            continue\n",
    "\n",
    "        start_time = source_times[vessel]\n",
    "        if node.time < start_time:\n",
    "            continue\n",
    "\n",
    "        for destination_port_number in all_port_numbers:\n",
    "            if destination_port_number == node.port.number:\n",
    "                arc_info_matrix = create_arc_info(speed=0, minimum_timesteps=1, departure=node.time, origin_port=node.port.number, destination_port=destination_port_number, lowest_speed=0, distance_to_port=0, vessel=vessel, is_waiting_arc=True)\n",
    "                node_arcs.append(arc_info_matrix)\n",
    "            else:\n",
    "                distance_nm = full_distance_matrix_nm[node.port.number - 1][destination_port_number - 1]\n",
    "                minimum_timesteps, speed = calculate_minimum_timesteps_and_speed(distance_nm=distance_nm)\n",
    "                arrival_time = node.time + minimum_timesteps\n",
    "                \n",
    "                if arrival_time < source_times[vessel] or arrival_time > NUM_TIME_PERIODS:\n",
    "                    continue\n",
    "\n",
    "                arc_info_matrix = create_arc_info(speed=speed, minimum_timesteps=minimum_timesteps, departure=node.time, origin_port=node.port.number, destination_port=destination_port_number, lowest_speed=MIN_SPEED, distance_to_port=distance_nm, vessel=vessel, is_waiting_arc=False)\n",
    "                node_arcs.append(arc_info_matrix)\n",
    "\n",
    "    return node_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arcs_to_nodes(all_info):\n",
    "    arc_dict = {}\n",
    "    vessel_arcs = {}\n",
    "    waiting_arcs = {}\n",
    "\n",
    "    for sublist in all_info:\n",
    "        for subsublist in sublist:\n",
    "            if not subsublist:\n",
    "                continue\n",
    "                \n",
    "            for tuple_data in subsublist:\n",
    "                speed, timesteps, departure, arrival, origin_port_number, destination_port_number, fuel_consumption, distance_nm, vessel, is_waiting_arc = tuple_data\n",
    "                cost = calc_cost(fuel_consumption)\n",
    "                origin_node_obj = NODE_DICT.get((origin_port_number, departure))\n",
    "                destination_node_obj = NODE_DICT.get((destination_port_number, arrival))\n",
    "\n",
    "                if origin_node_obj and destination_node_obj and arrival <= NUM_TIME_PERIODS:\n",
    "                    arc = Arc(origin_node=origin_node_obj, destination_node=destination_node_obj, distance=distance_nm, cost=cost + WAITING_COST, travel_time=timesteps, speed=speed, is_waiting_arc=is_waiting_arc)\n",
    "                    origin_node_obj.outgoing_arcs.add(arc)\n",
    "                    destination_node_obj.incoming_arcs.add(arc)\n",
    "                    arc_dict[(origin_node_obj.tuple, destination_node_obj.tuple, vessel)] = arc\n",
    "                    \n",
    "                    if is_waiting_arc:\n",
    "                        waiting_arcs.setdefault(vessel, []).append(arc)\n",
    "                    vessel_arcs.setdefault(vessel, []).append(arc)\n",
    "\n",
    "    return arc_dict, vessel_arcs, waiting_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate the information for the source arcs\n",
    "# source_arcs_info = [generate_source_arc_info(vessel, [port.number for port in ports], source_distances, sourceNode) for vessel in vessels]\n",
    "\n",
    "# Generate the information for the source arcs\n",
    "source_arcs_info = generate_source_arc_info(sourceNode)\n",
    "\n",
    "# Initialize the all_info list with the source arcs info\n",
    "all_info = source_arcs_info.copy()\n",
    "\n",
    "# Append the all_info list with the arcs for each node\n",
    "for vessel in vessels:\n",
    "    # For each node, create the outgoing arcs\n",
    "    arcs_for_current_vessel = [create_arcs_for_node(node, [vessel], [port.number for port in ports], start_times, full_distance_matrix_nm) for node in NODE_DICT.values()]\n",
    "    all_info.extend(arcs_for_current_vessel)\n",
    "    \n",
    "arc_dict, vessel_arcs, waiting_arcs = add_arcs_to_nodes(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arc_to_dict(origin, destination, vessel, arc_dict, vessel_arcs):\n",
    "    \"\"\"Helper function to add arc to dictionaries and nodes.\"\"\"\n",
    "    arc = Arc(origin_node=origin, destination_node=destination, distance=0, cost=0, travel_time=0, speed=0, is_waiting_arc=False)\n",
    "    origin.outgoing_arcs.add(arc)\n",
    "    destination.incoming_arcs.add(arc)\n",
    "    arc_dict[(origin.tuple, destination.tuple, vessel)] = arc\n",
    "    vessel_arcs.setdefault(vessel, []).append(arc)\n",
    "    return arc_dict, vessel_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sink_arcs(vessels, sinkNode, source_times, arc_dict, vessel_arcs):\n",
    "    for vessel in vessels:\n",
    "        # Arc from source node to sink node\n",
    "        arc_dict, vessel_arcs = add_arc_to_dict(sourceNode, sinkNode, vessel, arc_dict, vessel_arcs)\n",
    "        \n",
    "        # Arcs from other nodes to sink node\n",
    "        for node in NODE_DICT.values():\n",
    "            if node.port.number not in [0, len(ports) + 1] and node.time >= source_times[vessel]:\n",
    "                arc_dict, vessel_arcs = add_arc_to_dict(node, sinkNode, vessel, arc_dict, vessel_arcs)\n",
    "    \n",
    "    return arc_dict, vessel_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After calling add_arcs_to_nodes:\n",
    "arc_dict, vessel_arcs, waiting_arcs = add_arcs_to_nodes(all_info)\n",
    "\n",
    "# Then call create_sink_arcs with the returned arc_dict and vessel_arcs:\n",
    "arc_dict, vessel_arcs = create_sink_arcs(vessels, sinkNode, start_times, arc_dict, vessel_arcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXATE NUMBER OF VESSELS AND PORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read in the solution file and Find all port numbers\n",
    "with open(MIRP_SOL, 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "    # Regex pattern to find port numbers\n",
    "    pattern = r'Port (\\d+):'\n",
    "    ports_in_MIRP_SOL = re.findall(pattern, content)\n",
    "\n",
    "    # Converting port numbers to integers\n",
    "    port_numbers = [int(port) for port in ports_in_MIRP_SOL]\n",
    "    port_numbers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 1, Port 2, Port 3, Port 4, Port 5]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 2, Port 3]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all ports that are not in the solution but in ports\n",
    "ports_to_be_removed = [port for port in ports if port.number not in port_numbers]\n",
    "ports_to_be_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the arcs accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove all arcs from vessel_arcs that have destination port or origin port as the port to be removed\n",
    "for vessel in vessels:\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if arc.origin_node.port in ports_to_be_removed or arc.destination_node.port in ports_to_be_removed:\n",
    "            arc.origin_node.outgoing_arcs.remove(arc)\n",
    "            arc.destination_node.incoming_arcs.remove(arc)\n",
    "            del arc_dict[(arc.origin_node.tuple, arc.destination_node.tuple, vessel)]\n",
    "    vessel_arcs[vessel] = [arc for arc in vessel_arcs[vessel] if arc.origin_node.port not in ports_to_be_removed and arc.destination_node.port not in ports_to_be_removed]\n",
    "    \n",
    "    \n",
    "# Remove all arcs that have the vessel that we want to remove\n",
    "for vessel in vessels_to_remove:\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        arc.origin_node.outgoing_arcs.remove(arc)\n",
    "        arc.destination_node.incoming_arcs.remove(arc)\n",
    "        del arc_dict[(arc.origin_node.tuple, arc.destination_node.tuple, vessel)]\n",
    "    del vessel_arcs[vessel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = [vessel for vessel in vessels if vessel not in vessels_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 5, Vessel 7, Vessel 10, Vessel 11, Vessel 12]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all loading ports\n",
    "loading_ports = [port for port in ports if port.isLoadingPort==1]\n",
    "discharging_ports = [port for port in ports if port.isLoadingPort==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ports_to_be_removed from ports\n",
    "ports = [port for port in ports if port not in ports_to_be_removed]\n",
    "\n",
    "# Sum the rate for the ports that are removed\n",
    "lost_consumption = sum([port.rate for port in ports_to_be_removed])\n",
    "\n",
    "\n",
    "# Substract the lost consumption from the loading ports\n",
    "for port in loading_ports:\n",
    "    port.rate -= lost_consumption/len(loading_ports)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the nodes for the port to be removed\n",
    "nodes_to_remove = []\n",
    "\n",
    "for node in NODES:\n",
    "    if node.port in ports_to_be_removed:\n",
    "        del NODE_DICT[node.tuple]\n",
    "        nodes_to_remove.append(node)\n",
    "        \n",
    "NODES = [node for node in NODES if node not in nodes_to_remove]\n",
    "regularNodes = [node for node in regularNodes if node not in nodes_to_remove]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network for a given vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network_for_vessel(vessel, vessel_arcs, drop_sink_arcs):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node in NODES:\n",
    "        G.add_node(str(node.tuple))\n",
    "\n",
    "    # Add edges (arcs) to the graph\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        # If the arc goes to the sink node, skip it\n",
    "        if drop_sink_arcs and arc.destination_node == sinkNode:\n",
    "            continue\n",
    "        G.add_edge(str(arc.origin_node.tuple), str(arc.destination_node.tuple))\n",
    "\n",
    "    # Determine NODES with incoming and outgoing arcs\n",
    "    nodes_with_incoming_arcs = [node for node, degree in G.in_degree() if degree > 0]\n",
    "    nodes_with_outgoing_arcs = [node for node, degree in G.out_degree() if degree > 0]\n",
    "\n",
    "    # Create a list to hold node colors\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        if node in nodes_with_incoming_arcs or node in nodes_with_outgoing_arcs:\n",
    "            node_colors.append('green')  # Color for nodes with arcs\n",
    "        else:\n",
    "            node_colors.append('skyblue')  # Default color\n",
    "\n",
    "    # Resetting the y_offset and y_spacing\n",
    "    y_offset = 10\n",
    "    y_spacing = -30  # Increase vertical spacing for better clarity\n",
    "\n",
    "    # Manually specify the positions for each node\n",
    "    pos = {}\n",
    "\n",
    "    # Manually set the position for the source and sink nodes\n",
    "    # pos[\"(0, 0)\"] = (0, 0)  # Positioning source node at leftmost, middle height\n",
    "    # pos[\"(5, 5)\"] = (5 * 10, 0)  # Positioning sink node at rightmost, middle height\n",
    "\n",
    "    for node in NODES:\n",
    "        # Skip setting position for source and sink nodes\n",
    "        # if str(node.tuple) in [\"(0, 0)\", \"(5, 5)\"]:\n",
    "        #     continue\n",
    "        port_index = node.port.number  # Get port number to determine y-coordinate\n",
    "        # The x-coordinate is based on time, the y-coordinate is fixed for nodes with the same port\n",
    "        pos[str(node.tuple)] = (node.time * 10, port_index * y_spacing)  # Multiplying time by 10 for better horizontal spacing\n",
    "\n",
    "    # Drawing the graph using the adjusted positions\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=10)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    plt.title(\"Nodes and Arcs Graph\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vessel in vessels:\n",
    "#     visualize_network_for_vessel(vessel, vessel_arcs, drop_sink_arcs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def filter_arcs_for_equal_speed_spread(arcs):\n",
    "    if len(arcs) <= 4:\n",
    "        return arcs\n",
    "\n",
    "    # Sort arcs by speed\n",
    "    sorted_arcs = sorted(arcs, key=lambda arc: arc.speed)\n",
    "\n",
    "    slowest_arc = sorted_arcs[0]\n",
    "    fastest_arc = sorted_arcs[-1]\n",
    "\n",
    "    # To equally spread the speeds, we'll try to minimize the variance of the differences in speeds\n",
    "    # between consecutive selected arcs.\n",
    "    min_variance = float('inf')\n",
    "    selected_arcs = [slowest_arc, fastest_arc]\n",
    "\n",
    "    for i in range(1, len(sorted_arcs) - 2):\n",
    "        for j in range(i + 1, len(sorted_arcs) - 1):\n",
    "            speeds = [slowest_arc.speed, sorted_arcs[i].speed, sorted_arcs[j].speed, fastest_arc.speed]\n",
    "            intervals = [speeds[k + 1] - speeds[k] for k in range(len(speeds) - 1)]\n",
    "            variance = sum((x - sum(intervals) / len(intervals)) ** 2 for x in intervals) / len(intervals)\n",
    "\n",
    "            if variance < min_variance:\n",
    "                min_variance = variance\n",
    "                selected_arcs = [slowest_arc, sorted_arcs[i], sorted_arcs[j], fastest_arc]\n",
    "\n",
    "    return selected_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FA:\n",
    "    filtered_arcs = {}\n",
    "    for vessel in vessels:\n",
    "        arcs = vessel_arcs[vessel]\n",
    "\n",
    "        # Group arcs by (origin node, destination port)\n",
    "        grouped_arcs = defaultdict(list)\n",
    "        for arc in arcs:\n",
    "            origin_node = arc.origin_node\n",
    "            destination_port = arc.destination_node.port\n",
    "            grouped_arcs[(origin_node, destination_port)].append(arc)\n",
    "\n",
    "        # Filter arcs in each group\n",
    "        filtered_arcs_for_v = []\n",
    "\n",
    "        # print(grouped_arcs[NODE_DICT[(3, 5)], ports[0]])\n",
    "        for group in grouped_arcs:\n",
    "            filtered_arcs_for_v.extend(filter_arcs_for_equal_speed_spread(grouped_arcs[group]))\n",
    "        \n",
    "        filtered_arcs[vessel] = filtered_arcs_for_v\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_earliest_visits_from_start(filtered_arcs, start_node):\n",
    "    # Dictionary to store the earliest visit time for each port\n",
    "    earliest_visits = {}\n",
    "\n",
    "    # Filter arcs to include only those originating from the start node\n",
    "    outgoing_arcs = [arc for arc in filtered_arcs if arc.origin_node == start_node]\n",
    "\n",
    "    # Iterate through the outgoing arcs\n",
    "    for arc in outgoing_arcs:\n",
    "        dest_port = arc.destination_node.port\n",
    "        dest_time = arc.destination_node.time\n",
    "\n",
    "        # Update the earliest visit time for each destination port\n",
    "        if dest_port not in earliest_visits or dest_time < earliest_visits[dest_port]:\n",
    "            earliest_visits[dest_port] = dest_time\n",
    "\n",
    "    return earliest_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_visits = {}\n",
    "for vessel in vessels:\n",
    "    if FA:\n",
    "        earliest_visits[vessel] = find_earliest_visits_from_start(filtered_arcs[vessel], start_info[vessel])\n",
    "    else:\n",
    "        earliest_visits[vessel] = find_earliest_visits_from_start(vessel_arcs[vessel], start_info[vessel])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 5: {Port 1: 18, Port 4: 7, Port 5: 7, Port 6: 46},\n",
       " Vessel 7: {Port 1: 14, Port 4: 3, Port 5: 3, Port 6: 46},\n",
       " Vessel 10: {Port 1: 5, Port 4: 16, Port 5: 16, Port 6: 46},\n",
       " Vessel 11: {Port 1: 12, Port 4: 23, Port 5: 23, Port 6: 46},\n",
       " Vessel 12: {Port 1: 3, Port 4: 14, Port 5: 14, Port 6: 46}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FA:\n",
    "    filtered = filtered_arcs.copy()\n",
    "else:\n",
    "    filtered = vessel_arcs.copy()\n",
    "\n",
    "for v in vessels:\n",
    "    # Create a new list for storing filtered arcs\n",
    "    new_filtered_arcs = []\n",
    "\n",
    "    for arc in filtered[v]:\n",
    "        # Skip the source and sink nodes\n",
    "        # if arc.origin_node == sourceNode or arc.destination_node == sinkNode:\n",
    "        if arc.origin_node == sourceNode:\n",
    "            new_filtered_arcs.append(arc)\n",
    "            continue\n",
    "        \n",
    "        if arc.origin_node == start_info[v]:\n",
    "            new_filtered_arcs.append(arc)\n",
    "            continue\n",
    "\n",
    "        # Check the earliest visit time constraints\n",
    "        if arc.origin_node.time >= earliest_visits[v][arc.origin_node.port] \\\n",
    "           and arc.destination_node.time >= earliest_visits[v][arc.destination_node.port]:\n",
    "            new_filtered_arcs.append(arc)\n",
    "    filtered[v] = new_filtered_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of arcs before filtering: 6325\n",
      "Total number of arcs after filtering: 3067\n"
     ]
    }
   ],
   "source": [
    "total_vessel_arcs = sum(len(vessel_arcs[v]) for v in vessels)\n",
    "total_filtered_arcs = sum(len(filtered[v]) for v in vessels)\n",
    "\n",
    "# Print the total number of arcs for each vessel before and after filtering\n",
    "print(f\"Total number of arcs before filtering: {total_vessel_arcs}\")\n",
    "print(f\"Total number of arcs after filtering: {total_filtered_arcs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_arcs = filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the count of visits for each port for each vessel\n",
    "visit_count = {v: {p.number: 0 for p in ports} for v in vessels}\n",
    "\n",
    "# Update the visit count according to the vessel routes\n",
    "for v, route in VESSEL_ROUTES.items():\n",
    "    for p in route:\n",
    "        visit_count[v][p] += 1\n",
    "        \n",
    "all_o_indices = []\n",
    "for v in vessels:\n",
    "    for p in ports:\n",
    "        for t in TIME_PERIOD_RANGE:\n",
    "            for visit in range(1, visit_count[v][p.number] + 1):\n",
    "                index = (p.number, t, v, visit)\n",
    "                all_o_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each o_index in all_o_indices, find the corresponding index for the q_index\n",
    "all_q_indices = []\n",
    "for o_index in all_o_indices:\n",
    "    p, t, v, _ = o_index\n",
    "    q_index = (p, t, v)\n",
    "    all_q_indices.append(q_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_network_for_vessel(v, vessel_arcs, drop_sink_arcs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating the variables'''\n",
    "'''Binary first'''\n",
    "# x is the binary variable that indicates whether a vessel travels on arc a, where and arc is a route frome one node to another node.\n",
    "x = m.addVars(((arc.tuple, vessel) for vessel in vessels for arc in vessel_arcs[vessel]) , vtype=gp.GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Create o variables only for the number of visits that actually occur for each port for each vessel\n",
    "o = m.addVars((index for index in all_o_indices), vtype=gp.GRB.BINARY, name=\"o\") \n",
    "\n",
    "'''Continuous varibles'''\n",
    "# q is the amount of product loaded or unloaded at port i by vessel v at time t\n",
    "q_bounds = {(node.port.number, node.time, vessel): min(vessel.max_inventory, node.port.capacity) for node in regularNodes for vessel in vessels}\n",
    "q = m.addVars(q_bounds.keys(), lb=0, ub=q_bounds, vtype=gp.GRB.CONTINUOUS, name=\"q\")\n",
    "\n",
    "# s is the amount of product at port i at the end of period t\n",
    "s_bounds = {(node.port.number, node.time): node.port.capacity for node in regularNodes}\n",
    "s = m.addVars(s_bounds.keys(), lb=0, ub=s_bounds, vtype=gp.GRB.CONTINUOUS, name=\"s\")\n",
    "\n",
    "# Create s vars for each port in time period 0\n",
    "s_bounds_source = {(port.number, 0): port.capacity for port in ports}\n",
    "s_source = m.addVars(s_bounds_source.keys(), lb=0, ub=s_bounds, vtype=gp.GRB.CONTINUOUS, name=\"s\")\n",
    "s.update(s_source)\n",
    "\n",
    "# w is the amount of product on board of vessel v at the end of time period t\n",
    "w_bounds = {(t, vessel): vessel.max_inventory for vessel in vessels for t in TIME_PERIOD_RANGE}\n",
    "w = m.addVars(w_bounds.keys(), lb=0, ub=w_bounds, vtype=gp.GRB.CONTINUOUS, name=\"w\")\n",
    "w_bounds_source = {(0, vessel): vessel.max_inventory for vessel in vessels}\n",
    "w_source = m.addVars(w_bounds_source.keys(), lb=0, ub=w_bounds, vtype=gp.GRB.CONTINUOUS, name=\"w\")\n",
    "w.update(w_source)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3067, 720, 675, 138, 230)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(o), len(q), len(s), len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict where the arc.tuple is the key and arc.cost is the value\n",
    "\n",
    "costs = {(arc.tuple, vessel): arc.cost for vessel in vessels for arc in vessel_arcs[vessel] }\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = gp.quicksum(costs[key]*x[key] for key in costs) + gp.quicksum(o[node.port.number, node.time, vessel] * 50 for node in regularNodes for vessel in vessels)\n",
    "\n",
    "obj = gp.quicksum(costs[key] * x[key] for key in costs) + gp.quicksum(o[index] * OPERATING_COST for index in all_o_indices)\n",
    "\n",
    "\n",
    "#Minimize the costs\n",
    "m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (2)\n",
    "for v in vessels:\n",
    "    outgoing_from_source = [arc for arc in vessel_arcs[v] if arc.origin_node == sourceNode]\n",
    "    m.addConstr(gp.quicksum((x[arc.tuple, v]) for arc in outgoing_from_source) == 1, name = 'SourceFlow')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (3)\n",
    "for v in vessels:\n",
    "    incoming_to_sink = [arc for arc in vessel_arcs[v] if arc.destination_node == sinkNode]\n",
    "    m.addConstr(gp.quicksum((x[arc.tuple, v]) for arc in incoming_to_sink) == 1, name = 'SinkFlow')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (4)\n",
    "# Creating a flow balance constraint for each node\n",
    "\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        outgoing_from_node = [arc for arc in vessel_arcs[v] if arc.origin_node == node]\n",
    "        incoming_to_node = [arc for arc in vessel_arcs[v] if arc.destination_node == node]\n",
    "        m.addConstr(gp.quicksum((x[in_arc.tuple, v]) for in_arc in incoming_to_node) - gp.quicksum((x[out_arc.tuple, v]) for out_arc in outgoing_from_node) == 0, name = \"FlowBalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (5)\n",
    "for port in ports:\n",
    "    m.addConstr(s_source[port.number, 0] == port.inventory, name = 'InitialInventoryPort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (6)\n",
    "'''Rate is static for now'''\n",
    "# Inventory balance for ports at the end of each time period t\n",
    "for port in ports:\n",
    "    for t in TIME_PERIOD_RANGE:\n",
    "        m.addConstr(s[port.number, t] == (s[port.number, t-1] + (port.isLoadingPort * port.rate) - gp.quicksum(port.isLoadingPort * q[port.number, t, v] for v in vessels)) , name = 'InventoryBalance')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (7)\n",
    "\n",
    "for v in vessels:\n",
    "    m.addConstr(w_source[0, v] == v.inventory, name = 'InitialInventoryVessel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (8)\n",
    "\n",
    "# for each vessel, the inventory at the end of the time period is equal to the inventory at the beginning of the time period + the amount of product loaded/unloaded at the ports\n",
    "for t in TIME_PERIOD_RANGE:\n",
    "    for v in vessels:\n",
    "        m.addConstr(w[t, v] == gp.quicksum(port.isLoadingPort * q[port.number, t, v] for port in ports) + w[t-1,v], name = 'VesselBalance')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (9): Berth limit at each port in each time period\n",
    "for node in regularNodes:\n",
    "    for v in vessels:\n",
    "        # Find indices for o variables for the current vessel and port\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        m.addConstr((gp.quicksum(o[index] \n",
    "                                for index in o_indices ) \n",
    "                    <= node.port.berth_limit), \n",
    "                    name = f'Berth_limit_port_{node.port.number}_time_{node.time}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Constraint (10)\n",
    "\n",
    "for index in all_o_indices:\n",
    "    port_number, time, vessel, visit = index\n",
    "    node = NODE_DICT[(port_number, time)]\n",
    "    incoming_to_node = [arc for arc in vessel_arcs[vessel] if arc.destination_node == node]\n",
    "    m.addConstr(o[index] <= gp.quicksum((x[in_arc.tuple, vessel]) for in_arc in incoming_to_node), name = f'Operate_vessel_{vessel}_node_{node.port.number}_time_{node.time}_visit_{visit}')\n",
    "    \n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with all waiting arcs with key = (arc.tuple, v)\n",
    "# (node.port.number, node.time), (node.port.number, node.time + 1)\n",
    "all_waiting_arcs = {}\n",
    "for v in vessels:\n",
    "    for arc in waiting_arcs[v]:\n",
    "        origin_node = arc.origin_node\n",
    "        destination_node = arc.destination_node\n",
    "        all_waiting_arcs[((origin_node.port.number, origin_node.time),(destination_node.port.number, destination_node.time) , v)] = arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (11)\n",
    "                \n",
    "for index in all_o_indices:\n",
    "    port_number, time, vessel, visit = index\n",
    "    node = NODE_DICT[(port_number, time)]\n",
    "    if (node.port.number, node.time + 1, vessel, visit + 1) in o.keys():  # check if o for the next period and next visit exists\n",
    "        waiting_arc_key = ((node.port.number, node.time), (node.port.number, node.time + 1), vessel)\n",
    "        if waiting_arc_key in all_waiting_arcs.keys():\n",
    "            waiting_arc = all_waiting_arcs[waiting_arc_key]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        actual_key = (waiting_arc.tuple, vessel)\n",
    "        \n",
    "        if actual_key in x.keys():  # check if the waiting arc exists\n",
    "            m.addConstr(o[index] <= \n",
    "                        o[(node.port.number, node.time + 1, vessel, visit + 1)] + \n",
    "                        (1 - x[actual_key]),\n",
    "                        name=f\"Operate_or_Move_{node.port.number}_{node.time}_{vessel}_visit_{visit}\")\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constraint (12): The quantity of product loaded or unloaded must not exceed the maximum operating quantity for each operation\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        # Find o-indices for the current node and vessel\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        m.addConstr(q[node.port.number, node.time, v] <= gp.quicksum(o[index] for index in o_indices) * v.max_operating_quantity,\n",
    "                    name=f'Max_operating_quantity_vessel_{v}_port_{node.port.number}_time_{node.time}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constraint 13\n",
    "        \n",
    "# Constraint 14: Each vessel can perform at most one operation per time period across all ports and visits\n",
    "for v in vessels:\n",
    "    for t in TIME_PERIOD_RANGE:\n",
    "        # Find the set of all o-indices for the current vessel and node\n",
    "        o_indices = [index for index in all_o_indices if index[1] == t and index[2] == v]\n",
    "        m.addConstr(gp.quicksum(o[index] for index in o_indices) <= 1,\n",
    "                    name=f'Only_one_operation_per_time_period_vessel_{v}_time_{t}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Constraint 14: Each vessel must complete its sequence by performing an operation at the last port in its sequence\n",
    "for v in vessels:\n",
    "    if VESSEL_ROUTES[v]:\n",
    "        last_port_in_sequence = VESSEL_ROUTES[v][-1]\n",
    "        last_visit_count = VESSEL_ROUTES[v].count(last_port_in_sequence)\n",
    "        m.addConstr(gp.quicksum(o[last_port_in_sequence, t, v, last_visit_count] for t in TIME_PERIOD_RANGE) >= 1,\n",
    "                    name=f'Sequence_completion_constraint_vessel_{v}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 15: Limit the number of operations at each port for each vessel as per visit_count\n",
    "for v in vessels:\n",
    "    for p in ports:\n",
    "        # visit_count[v][p.number] gives the allowed number of visits to port p for vessel v\n",
    "        allowed_visits = visit_count[v][p.number]\n",
    "\n",
    "        # Sum over all time periods and all visits (up to allowed_visits) should not exceed allowed_visits\n",
    "        m.addConstr(\n",
    "            gp.quicksum(o[p.number, t, v, visit] for t in TIME_PERIOD_RANGE for visit in range(1, allowed_visits + 1)) <= allowed_visits,\n",
    "            name=f'Operation_limit_vessel_{v}_port_{p.number}'\n",
    "        )\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constraint 16: Enforcing the correct sequence of operations\n",
    "for v in vessels:\n",
    "    sequence = VESSEL_ROUTES[v]\n",
    "    visit_counts = {port: 0 for port in sequence}\n",
    "    \n",
    "    for i in range(1, len(sequence)):\n",
    "        this_port = sequence[i-1]\n",
    "        next_port = sequence[i]\n",
    "        visit_counts[this_port] += 1\n",
    "        this_visit = visit_counts[this_port]\n",
    "        next_visit = visit_counts[next_port] + 1\n",
    "        \n",
    "        # For each time period, ensure the operation at next_port follows the operation at this_port\n",
    "        for t in TIME_PERIOD_RANGE:\n",
    "            # Sum of operations at this_port for all time periods up to t-1 must be greater than or equal to\n",
    "            # the sum of operations at next_port for all time periods up to t\n",
    "            m.addConstr(\n",
    "                gp.quicksum(o[this_port, t_prime, v, this_visit] for t_prime in TIME_PERIOD_RANGE if t_prime < t) >=\n",
    "                gp.quicksum(o[next_port, t_prime, v, next_visit] for t_prime in TIME_PERIOD_RANGE if t_prime <= t),\n",
    "                name=f'Sequence_{v}_this_{this_port}_{this_visit}_next_{next_port}_{next_visit}_time_{t}'\n",
    "            )\n",
    "m.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (17) modification\n",
    "# Ensure that q is at least 1/4 of the vessel's capacity if o is 1\n",
    "\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        for index in o_indices:\n",
    "            m.addConstr(q[node.port.number, node.time, v] >= 1/4 * v.max_inventory * o[index], name=f'q_{node.port.number}_{node.time}_{v}_visit_{visit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8257U CPU @ 1.40GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 4771 rows, 4830 columns and 39780 nonzeros\n",
      "Model fingerprint: 0x426166a7\n",
      "Variable types: 1043 continuous, 3787 integer (3787 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [5e+01, 3e+05]\n",
      "  Bounds range     [1e+00, 7e+02]\n",
      "  RHS range        [1e+00, 3e+02]\n",
      "Presolve removed 2999 rows and 1888 columns\n",
      "Presolve time: 0.32s\n",
      "Presolved: 1772 rows, 2942 columns, 16857 nonzeros\n",
      "Variable types: 414 continuous, 2528 integer (2528 binary)\n",
      "\n",
      "Root relaxation: objective 3.973590e+05, 1901 iterations, 0.05 seconds (0.06 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 397359.019    0  387          - 397359.019      -     -    0s\n",
      "     0     0 609201.760    0  412          - 609201.760      -     -    0s\n",
      "     0     0 609241.760    0  413          - 609241.760      -     -    0s\n",
      "     0     0 784593.102    0  345          - 784593.102      -     -    0s\n",
      "     0     0 1328532.40    0  277          - 1328532.40      -     -    1s\n",
      "     0     0 1330226.02    0  277          - 1330226.02      -     -    1s\n",
      "     0     0 1330226.02    0  278          - 1330226.02      -     -    1s\n",
      "     0     0 1361905.00    0  283          - 1361905.00      -     -    1s\n",
      "     0     0 1362573.09    0  279          - 1362573.09      -     -    1s\n",
      "     0     0 1362581.35    0  280          - 1362581.35      -     -    1s\n",
      "     0     0 1380781.04    0  223          - 1380781.04      -     -    1s\n",
      "     0     0 1385078.74    0  263          - 1385078.74      -     -    1s\n",
      "     0     0 1386769.82    0  282          - 1386769.82      -     -    1s\n",
      "     0     0 1386981.76    0  287          - 1386981.76      -     -    1s\n",
      "     0     0 1392952.13    0  256          - 1392952.13      -     -    1s\n",
      "     0     0 1392953.42    0  256          - 1392953.42      -     -    1s\n",
      "     0     0 1392965.10    0  267          - 1392965.10      -     -    1s\n",
      "     0     0 1392971.52    0  267          - 1392971.52      -     -    1s\n",
      "     0     0 1392972.94    0  264          - 1392972.94      -     -    1s\n",
      "     0     0 1392974.92    0  259          - 1392974.92      -     -    1s\n",
      "     0     0 1392975.18    0  264          - 1392975.18      -     -    1s\n",
      "     0     0 1392976.31    0  270          - 1392976.31      -     -    1s\n",
      "     0     0 1392976.69    0  268          - 1392976.69      -     -    1s\n",
      "     0     0 1393023.02    0  253          - 1393023.02      -     -    1s\n",
      "     0     0 1393023.02    0  261          - 1393023.02      -     -    1s\n",
      "     0     0 1393061.25    0  261          - 1393061.25      -     -    1s\n",
      "     0     0 1393061.41    0  258          - 1393061.41      -     -    1s\n",
      "     0     0 1393061.41    0  249          - 1393061.41      -     -    1s\n",
      "     0     2 1393173.55    0  249          - 1393173.55      -     -    2s\n",
      "*  335   241              66    2862326.1877 1400723.31  51.1%  41.7    2s\n",
      "H  388   254                    2826644.7031 1481829.35  47.6%  41.9    2s\n",
      "H  429   248                    2632161.0658 1481829.35  43.7%  40.8    3s\n",
      "H  472   261                    2632061.0658 1503332.47  42.9%  41.7    3s\n",
      "H  486   234                    2580419.6903 1503332.47  41.7%  41.5    3s\n",
      "H  524   247                    2580319.6903 1503332.47  41.7%  40.4    3s\n",
      "H 1092   477                    2552395.0947 2473770.60  3.08%  38.2    4s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 20\n",
      "  Implied bound: 2\n",
      "  Clique: 1\n",
      "  MIR: 9\n",
      "  Flow cover: 11\n",
      "  Flow path: 4\n",
      "  Inf proof: 1\n",
      "  Zero half: 26\n",
      "  RLT: 4\n",
      "\n",
      "Explored 1093 nodes (51100 simplex iterations) in 4.83 seconds (4.00 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 7: 2.5524e+06 2.58032e+06 2.58042e+06 ... 2.86233e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.552395094675e+06, best bound 2.552395094675e+06, gap 0.0000%\n",
      "Optimal solution found!\n"
     ]
    }
   ],
   "source": [
    "#optimize the model\n",
    "# Assuming you have a Gurobi model object named 'model' and a variable named 'arc_vars' representing the arcs\n",
    "\n",
    "# Possibility of setting a time limit\n",
    "# m.setParam(gp.GRB.Param.TimeLimit, 30)\n",
    "\n",
    "# Optimize the model\n",
    "m.optimize()\n",
    "\n",
    "# Check the status of the optimization\n",
    "if m.status == gp.GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found!\")\n",
    "    \n",
    "# If the model is infeasible, compute the IIS\n",
    "if m.status == gp.GRB.INFEASIBLE:\n",
    "    print('Model is infeasible')\n",
    "    m.computeIIS()\n",
    "    # Write the IIS to a .ilp file\n",
    "    m.write(\"model.ilp\")\n",
    "    print('The infeasibility is written to the file \"model.ilp\"')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value: 2552395.0946747046\n"
     ]
    }
   ],
   "source": [
    "print(f'Objective value: {m.objVal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each vessel, save the route\n",
    "vessel_routes_incl_wa = {}\n",
    "for vessel in vessels:\n",
    "    vessel_routes_incl_wa[vessel] = []\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if x[arc.tuple, vessel].x > 0:\n",
    "            vessel_routes_incl_wa[vessel].append(arc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arcs in each route by time\n",
    "for vessel in vessels:\n",
    "    vessel_routes_incl_wa[vessel] = sorted(vessel_routes_incl_wa[vessel], key=lambda x: x.origin_node.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 5: [5, 1, 5],\n",
       " Vessel 7: [4, 1, 4, 1],\n",
       " Vessel 10: [1, 4, 1, 5],\n",
       " Vessel 11: [1, 4, 1],\n",
       " Vessel 12: [1, 5]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VESSEL_ROUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0) -> (5, 6) --- Cost: 50 --- Speed: 0,\n",
       " (5, 6) -> (4, 7) --- Cost: 2170.112839952395 --- Speed: 8,\n",
       " (4, 7) -> (1, 21) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       " (1, 21) -> (5, 33) --- Cost: 315288.75815244415 --- Speed: 14.195389368850492,\n",
       " (5, 33) -> (6, 46) --- Cost: 0 --- Speed: 0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "vessel_routes_incl_wa[vessels[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 5: [(0, 0) -> (5, 6) --- Cost: 50 --- Speed: 0,\n",
       "  (5, 6) -> (4, 7) --- Cost: 2170.112839952395 --- Speed: 8,\n",
       "  (4, 7) -> (1, 21) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (1, 21) -> (5, 33) --- Cost: 315288.75815244415 --- Speed: 14.195389368850492,\n",
       "  (5, 33) -> (6, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 7: [(0, 0) -> (4, 2) --- Cost: 50 --- Speed: 0,\n",
       "  (4, 2) -> (1, 16) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (1, 16) -> (4, 30) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (4, 30) -> (1, 44) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (1, 44) -> (6, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 10: [(0, 0) -> (1, 4) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 4) -> (1, 5) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 5) -> (4, 17) --- Cost: 299952.5065953568 --- Speed: 13.96135184185265,\n",
       "  (4, 17) -> (1, 31) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (1, 31) -> (5, 45) --- Cost: 231653.9855813876 --- Speed: 12.167476601871849,\n",
       "  (5, 45) -> (6, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 11: [(0, 0) -> (1, 11) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 11) -> (4, 25) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (4, 25) -> (1, 39) --- Cost: 220386.53545781315 --- Speed: 11.966873007302272,\n",
       "  (1, 39) -> (6, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 12: [(0, 0) -> (1, 2) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 2) -> (5, 19) --- Cost: 157123.98330087186 --- Speed: 10.020274848600346,\n",
       "  (5, 19) -> (6, 46) --- Cost: 0 --- Speed: 0]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessel_routes_incl_wa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 5: [5, 4, 1, 5, 6],\n",
       " Vessel 7: [4, 1, 4, 1, 6],\n",
       " Vessel 10: [1, 4, 1, 5, 6],\n",
       " Vessel 11: [1, 4, 1, 6],\n",
       " Vessel 12: [1, 5, 6]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each vessel, save the route, but only the port-sequence\n",
    "vessel_routes_seq = {}\n",
    "for vessel in vessels:\n",
    "    vessel_routes_seq[vessel] = []\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if arc in waiting_arcs[vessel]:\n",
    "            continue\n",
    "        if x[arc.tuple, vessel].x > 0:\n",
    "            vessel_routes_seq[vessel].append(arc.destination_node.port.number)\n",
    "vessel_routes_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_solution_for_vessel(vessel, vessel_arcs):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node in NODES:\n",
    "        G.add_node(str(node.tuple))\n",
    "\n",
    "    # Add edges (arcs) to the graph\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        G.add_edge(str(arc.origin_node.tuple), str(arc.destination_node.tuple))\n",
    "\n",
    "    # Determine nodes with incoming and outgoing arcs\n",
    "    nodes_with_incoming_arcs = [node for node, degree in G.in_degree() if degree > 0]\n",
    "    nodes_with_outgoing_arcs = [node for node, degree in G.out_degree() if degree > 0]\n",
    "\n",
    "   # Create a list to hold node colors\n",
    "    node_colors = []\n",
    "    for node_str in G.nodes():\n",
    "        port_number, time = eval(node_str)  # Extract port number and time from the node label\n",
    "        q_value = q.get((port_number, time, vessel))  # Use .get() to safely access the dictionary\n",
    "        if q_value and q_value.x > 0 + EBS:\n",
    "            node_colors.append('brown')  # Color for nodes with non-zero q values\n",
    "        elif node_str in nodes_with_incoming_arcs or node_str in nodes_with_outgoing_arcs:\n",
    "            node_colors.append('green')  # Color for nodes with arcs\n",
    "        \n",
    "        else:\n",
    "            node_colors.append('skyblue')  # Default color for nodes without arcs or q values\n",
    "\n",
    "\n",
    "    # Resetting the y_offset and y_spacing\n",
    "    y_offset = 10\n",
    "    y_spacing = -30  # Increase vertical spacing for better clarity\n",
    "\n",
    "    # Manually specify the positions for each node\n",
    "    pos = {}\n",
    "    for node_str in G.nodes():\n",
    "        port_number, time = eval(node_str)  # Extract port number and time from the node label\n",
    "        # The x-coordinate is based on time, the y-coordinate is fixed for nodes with the same port\n",
    "        pos[node_str] = (time * 10, port_number * y_spacing)  # Multiplying time by 10 for better horizontal spacing\n",
    "\n",
    "    # Drawing the graph using the adjusted positions\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=10)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    plt.title(f\"Nodes and Arcs Graph for {vessel}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o[1,21,Vessel 5,1] 1.0\n",
      "o[5,6,Vessel 5,1] 1.0\n",
      "o[5,33,Vessel 5,2] 1.0\n",
      "o[1,16,Vessel 7,1] 1.0\n",
      "o[1,44,Vessel 7,2] 1.0\n",
      "o[4,2,Vessel 7,1] 1.0\n",
      "o[4,30,Vessel 7,2] 1.0\n",
      "o[1,5,Vessel 10,1] 1.0\n",
      "o[1,31,Vessel 10,2] 1.0\n",
      "o[4,17,Vessel 10,1] 1.0\n",
      "o[5,45,Vessel 10,1] 1.0\n",
      "o[1,11,Vessel 11,1] 1.0\n",
      "o[1,39,Vessel 11,2] 1.0\n",
      "o[4,25,Vessel 11,1] 1.0\n",
      "o[1,2,Vessel 12,1] 1.0\n",
      "o[5,19,Vessel 12,1] 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the o vars\n",
    "for index in all_o_indices:\n",
    "    if o[index].x > 0:\n",
    "        print(o[index].varName, o[index].x)\n",
    "# for v in vessels:\n",
    "#     for node in regularNodes:\n",
    "#         for numvisits in range(1, MAX_VISITS[v] + 1):\n",
    "#             if o[node.port.number, node.time, v, numvisits].x > 0:\n",
    "#                 print(o[node.port.number, node.time, v, numvisits].varName, o[node.port.number, node.time, v, numvisits].x)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_solution_for_vessel(v, vessel_routes_incl_wa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_network_for_vessel(v, vessel_arcs, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all x-vars that are 1\n",
    "active_arcs = {}\n",
    "for v in vessels:\n",
    "    v_arcs_active = []\n",
    "    for arc in vessel_arcs[v]:\n",
    "        if x[arc.tuple, v].x > 0 + EBS:\n",
    "            v_arcs_active.append(arc)\n",
    "    active_arcs[v] = v_arcs_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(filepath):\n",
    "    # Open a file to write the results\n",
    "    with open(filepath, 'w') as file:\n",
    "        \n",
    "        file.write(\"Hyperparameters:\\n\")\n",
    "        file.write(f\"Number of Time Periods: {NUM_TIME_PERIODS}\\n\")\n",
    "        file.write(f\"Time Period Range: {TIME_PERIOD_RANGE}\\n\")\n",
    "        file.write(f\"Original Number of Vessels: {ORIGINAL_NUM_VESSELS}\\n\")\n",
    "        file.write(f\"Number of Vessels: {NUM_VESSELS}\\n\")\n",
    "        file.write(f\"Max Speed: {MAX_SPEED}\\n\")\n",
    "        file.write(f\"Min Speed: {MIN_SPEED}\\n\")\n",
    "        file.write(f\"Operating Speed: {OPERATING_SPEED}\\n\")\n",
    "        file.write(f\"Operating Cost: {OPERATING_COST}\\n\")\n",
    "        file.write(f\"Waiting Cost: {WAITING_COST}\\n\")\n",
    "        file.write(f\"Fuel Price (USD/ton): {FUEL_PRICE}\\n\\n\")\n",
    "        file.write(f\"Number of ports: {NUM_PORTS}\\n\\n\")\n",
    "        \n",
    "        file.write(\"\\nPorts:\\n\")\n",
    "        for port in ports:\n",
    "            file.write(f\"{port.__repr2__()}\\n\")\n",
    "            \n",
    "        file.write(\"\\nVessels:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel.__repr2__()}\\n\")\n",
    "        \n",
    "        file.write(\"\\nFull distance matrix:\\n\")\n",
    "        for row in FULL_DISTANCE_MATRIX:\n",
    "            row_str = ', '.join([f\"{item:.4f}\" for item in row])  # Format each item in the row\n",
    "            file.write(f\"[{row_str}]\\n\")\n",
    "            \n",
    "        file.write(\"\\n Start times:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel}: {start_times[vessel]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(\"----------------------------------------\\n\")\n",
    "        # Write the objective value\n",
    "        file.write(f\"Objective Value: {m.objVal}\\n\")    \n",
    "        file.write(\"----------------------------------------\\n\")\n",
    "        \n",
    "        # Log the GAP\n",
    "        file.write(\"\\nOptimality Gap:\\n\")\n",
    "        gap_percentage = m.MIPGap * 100  # Convert to percentage\n",
    "        file.write(f\"Current GAP: {gap_percentage:.2f}%\\n\")\n",
    "        \n",
    "        file.write(\"\\nVessel Routes:\\n\")\n",
    "        for vessel, route in vessel_routes_seq.items():\n",
    "            file.write(f\"{vessel}: {route}\\n\")\n",
    "            \n",
    "        # Write the active arcs to file\n",
    "        file.write(\"\\nActive Arcs:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel}: {[arc for arc in active_arcs[vessel]]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "        # Write the values of all variables\n",
    "        file.write(\"Variable Values:\\n\")\n",
    "        for var in m.getVars():\n",
    "            file.write(f\"{var.varName}: {var.x}\\n\")\n",
    "            \n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG:\n",
    "    log(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
