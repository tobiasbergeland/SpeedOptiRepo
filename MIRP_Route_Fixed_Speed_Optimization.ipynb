{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTANCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INSTANCE = 'LR1_1_DR1_3_VC1_V7a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V8a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V9a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V11a'\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V12a'\n",
    "# INSTANCE = 'LR1_2_DR1_3_VC2_V6a'\n",
    "\n",
    "# INSTANCE = 'LR1_1_DR1_4_VC3_V12b'\n",
    "# INSTANCE = 'LR1_2_DR1_3_VC3_V8a'\n",
    "# INSTANCE = 'LR2_11_DR2_22_VC3_V6a'\n",
    "# INSTANCE = 'LR2_11_DR2_33_VC4_V11a'\n",
    "\n",
    "INSTANCE_PATH = INSTANCE+'/'+INSTANCE+'.txt'\n",
    "VESSELINFO_PATH = INSTANCE+'/vessel_data.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG = True\n",
    "\n",
    "# FA = True\n",
    "FA = False\n",
    "\n",
    "if FA:\n",
    "    FILEPATH = f'new_official_solutions/{INSTANCE}/MIRP_RF_SPEED_OPTI_results_{INSTANCE}_45_FA.txt'\n",
    "else:\n",
    "    FILEPATH = f'new_official_solutions/{INSTANCE}/MIRP_RF_SPEED_OPTI_results_{INSTANCE}_45_NA.txt'\n",
    "\n",
    "# FILEPATH = 'solutions/MIRP_RF_SPEED_OPTI_GARBAGE.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MIRP-Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MIRP_SOL = f'new_official_solutions/{INSTANCE}/MIRP_operating_speed_results_{INSTANCE}_45_noGR.txt'\n",
    "# MIRP_SOL = 'solutions/MIRP_operating_speed_GARBAGE.txt'\n",
    "\n",
    "# MIRP_operating_speed_results_LR1_1_DR1_3_VC1_V7a_45_noGR\n",
    "# new_official_solutions/LR1_1_DR1_3_VC1_V7a/MIRP_operating_speed_results_LR1_1_DR1_3_VC1_V7a_45_noGR.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2024-01-18\n"
     ]
    }
   ],
   "source": [
    "m = gp.Model('MIRP Route Fixed with Speed Optimization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating classes in order organize the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Port:\n",
    "    def __init__(self, capacity, inventory, rate, price, berth_limit, port_fee, max_amount, min_amount, number, isLoadingPort):\n",
    "        self.capacity = capacity\n",
    "        self.inventory = inventory\n",
    "        self.rate = rate\n",
    "        self.price = price \n",
    "        self.berth_limit = berth_limit \n",
    "        self.port_fee = port_fee\n",
    "        self.max_amount = max_amount\n",
    "        self.min_amount = min_amount\n",
    "        self.number = number\n",
    "        self.isLoadingPort = isLoadingPort\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Port {self.number}'\n",
    "    \n",
    "    def __repr2__(self):\n",
    "        return f'Port {self.number}: Capacity = {self.capacity}, Inventory = {self.inventory}, Rate = {self.rate}, Price = {self.price}, Berth Limit = {self.berth_limit}, Port Fee = {self.port_fee}, Max Amount = {self.max_amount}, Min Amount = {self.min_amount}, is Loading Port = {self.isLoadingPort}'\n",
    "        \n",
    "    \n",
    "\n",
    "class Node:\n",
    "    def __init__(self, port, time):\n",
    "        self.port = port\n",
    "        self.time = time\n",
    "        self.tuple = (port.number if port else None, time)\n",
    "        self.incoming_arcs = set()\n",
    "        self.outgoing_arcs = set()\n",
    "        self.berths = port.berth_limit if port else None\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return str(self.tuple)\n",
    "\n",
    "\n",
    "class Arc:\n",
    "    def __init__(self, origin_node, destination_node, distance, cost, travel_time, speed, is_waiting_arc):\n",
    "        self.origin_node = origin_node\n",
    "        self.destination_node = destination_node\n",
    "        self.tuple = (origin_node, destination_node)\n",
    "        self.distance = distance\n",
    "        self.cost = cost\n",
    "        self.travel_time = travel_time\n",
    "        self.speed = speed\n",
    "        self.is_waiting_arc = is_waiting_arc\n",
    "            \n",
    "    def __repr__(self):\n",
    "        return f'{self.origin_node} -> {self.destination_node} --- Cost: {self.cost} --- Speed: {self.speed}'\n",
    "\n",
    "class Vessel:\n",
    "    def __init__(self, max_inventory, initial_inventory, max_operating_quantity, number):\n",
    "        self.max_inventory = int(max_inventory)\n",
    "        self.inventory = initial_inventory\n",
    "        self.max_operating_quantity = max_operating_quantity\n",
    "        self.number = number\n",
    "        self.arcs = set()\n",
    "        self.all_arcs_v = set()\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return f'Vessel {self.number}'\n",
    "\n",
    "    def __repr2__(self):\n",
    "        return f'Vessel {self.number}: Max Inventory = {self.max_inventory}, Inventory = {self.inventory}, Max Operating Quantity = {self.max_operating_quantity}'\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the content of the provided file\n",
    "with open(INSTANCE_PATH, 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_metadata(content):\n",
    "    metadata = {}\n",
    "    start_index = content.index(\"----- MetaData -----\") + len(\"----- MetaData -----\")\n",
    "    end_index = content.find(\"\\n\\n\", start_index) if \"\\n\\n\" in content[start_index:] else len(content)\n",
    "    metadata_section = content[start_index:end_index].strip().split(\"\\n\")\n",
    "    \n",
    "    for line in metadata_section:\n",
    "        if \":\" in line:\n",
    "            key, value = line.split(\":\", 1)\n",
    "            metadata[key.strip()] = value.strip()\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "def safe_convert(value, data_type):\n",
    "    try:\n",
    "        if data_type == 'int':\n",
    "            return int(value)\n",
    "        elif data_type == 'float':\n",
    "            return float(value)\n",
    "        elif data_type == 'list':\n",
    "            # Handle different list formats\n",
    "            if value.startswith('[') and value.endswith(']'):\n",
    "                # Remove brackets, split by comma and strip spaces\n",
    "                return [int(x.strip()) for x in value[1:-1].split(',')]\n",
    "            else:\n",
    "                # Split by space or other delimiters if necessary\n",
    "                return [int(x.strip()) for x in value.split()]\n",
    "    except (ValueError, TypeError):\n",
    "        return None\n",
    "\n",
    "\n",
    "def read_and_assign_metadata_from_content(content):\n",
    "    metadata = parse_metadata(content)\n",
    "    \n",
    "    numPeriods = safe_convert(metadata.get('numPeriods', '').split()[-1], 'int')\n",
    "    numCommodities = safe_convert(metadata.get('numCommodities'), 'int')\n",
    "    numLoadingRegions = safe_convert(metadata.get('numLoadingRegions'), 'int')\n",
    "    numDischargingRegions = safe_convert(metadata.get('numDischargingRegions'), 'int')\n",
    "    numLoadingPortsInRegion = safe_convert(metadata.get('numLoadingPortsInRegion', '[]'), 'list')\n",
    "    numDischargingPortsInRegion = safe_convert(metadata.get('numDischargingPortsInRegion', '[]'), 'list')\n",
    "    numVesselClasses = safe_convert(metadata.get('numVesselClasses'), 'int')\n",
    "    numTermVesselsInClass = safe_convert(metadata.get('numTermVesselsInClass', '[]'), 'list')\n",
    "    hoursPerPeriod = safe_convert(metadata.get('hoursPerPeriod'), 'int')\n",
    "    spotMarketPricePerUnit = safe_convert(metadata.get('spotMarketPricePerUnit'), 'float')\n",
    "    spotMarketDiscountFactor = safe_convert(metadata.get('spotMarketDiscountFactor'), 'float')\n",
    "    perPeriodRewardForFinishingEarly = safe_convert(metadata.get('perPeriodRewardForFinishingEarly', '0'), 'float')\n",
    "    attemptCost = safe_convert(metadata.get('attemptCost', '0'), 'float')\n",
    "    constantForSinglePeriodAlphaSlack = safe_convert(metadata.get('constantForSinglePeriodAlphaSlack', '0'), 'float')\n",
    "    constantForCumulativeAlphaSlack = safe_convert(metadata.get('constantForCumulativeAlphaSlack', '0'), 'float')\n",
    "    \n",
    "    return {\n",
    "        'numPeriods': numPeriods,\n",
    "        'numCommodities': numCommodities,\n",
    "        'numLoadingRegions': numLoadingRegions,\n",
    "        'numDischargingRegions': numDischargingRegions,\n",
    "        'numLoadingPortsInRegion': numLoadingPortsInRegion,\n",
    "        'numDischargingPortsInRegion': numDischargingPortsInRegion,\n",
    "        'numVesselClasses': numVesselClasses,\n",
    "        'numTermVesselsInClass': numTermVesselsInClass,\n",
    "        'hoursPerPeriod': hoursPerPeriod,\n",
    "        'spotMarketPricePerUnit': spotMarketPricePerUnit,\n",
    "        'spotMarketDiscountFactor': spotMarketDiscountFactor,\n",
    "        'perPeriodRewardForFinishingEarly': perPeriodRewardForFinishingEarly,\n",
    "        'attemptCost': attemptCost,\n",
    "        'constantForSinglePeriodAlphaSlack': constantForSinglePeriodAlphaSlack,\n",
    "        'constantForCumulativeAlphaSlack': constantForCumulativeAlphaSlack\n",
    "    }\n",
    "\n",
    "# Using the refactored function with the already-read content\n",
    "metadata_from_content = read_and_assign_metadata_from_content(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual adjustments for the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''We only handle one vesseltype for now'''\n",
    "metadata_from_content['numVesselClasses'] = 1\n",
    "# Therefore we set all of the vessels to be of the same type. Type 1\n",
    "vessels_in_classes = metadata_from_content['numTermVesselsInClass']\n",
    "metadata_from_content['numTermVesselsInClass'] = [sum(vessels_in_classes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change the numPeriods manually.\n",
    "ORIGINAL_NUM_TIME_PERIODS = metadata_from_content['numPeriods']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vessel info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VESSELINFO_PATH, 'r') as file:\n",
    "    file_content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Vessel_0': {'Initial Inventory': 300,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_2',\n",
       "  'First Time Available': 6},\n",
       " 'Vessel_1': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 7},\n",
       " 'Vessel_2': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 0},\n",
       " 'Vessel_3': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 5},\n",
       " 'Vessel_4': {'Initial Inventory': 0,\n",
       "  'Initial Port': 'LoadingRegion_0_Port_0',\n",
       "  'First Time Available': 2},\n",
       " 'Vessel_5': {'Initial Inventory': 300,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_0',\n",
       "  'First Time Available': 1},\n",
       " 'Vessel_6': {'Initial Inventory': 300,\n",
       "  'Initial Port': 'DischargeRegion_0_Port_1',\n",
       "  'First Time Available': 4}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Regular expression to extract vessel information including first time available\n",
    "pattern = r\"name\\s+Vessel_(\\d+)\\s+.*?initialInventory\\s+(\\d+)\\s+initialPort\\s+([\\w_]+)\\s+firstTimeAvailable\\s+(\\d+)\"\n",
    "\n",
    "# Finding all matches\n",
    "vessel_info = re.findall(pattern, file_content, re.DOTALL)\n",
    "\n",
    "# Creating a dictionary to store the information\n",
    "vessel_data = {}\n",
    "for vessel in vessel_info:\n",
    "    vessel_index = int(vessel[0])\n",
    "    initial_inventory = int(vessel[1])\n",
    "    initial_port = vessel[2]\n",
    "    first_time_available = int(vessel[3])\n",
    "\n",
    "    # Storing in dictionary\n",
    "    vessel_data[f\"Vessel_{vessel_index}\"] = {\n",
    "        \"Initial Inventory\": initial_inventory,\n",
    "        \"Initial Port\": initial_port,\n",
    "        \"First Time Available\": first_time_available\n",
    "    }\n",
    "\n",
    "vessel_data  # Displaying the dictionary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in port data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_region_table(content):\n",
    "    # Extract the region table section\n",
    "    start_index = content.index(\"----- Region Table ----\") + len(\"----- Region Table ----\")\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    region_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "    regions = {}\n",
    "    for line in region_section:\n",
    "        if \"Note:\" not in line:  # Exclude the note lines\n",
    "            attribute, *values = line.split()\n",
    "            regions[attribute] = values\n",
    "    return regions\n",
    "\n",
    "\n",
    "def parse_port_table_for_region(content, region_index):\n",
    "    # Extract the port table section for the specified region\n",
    "    search_str = f\"----- Port Table For Region {region_index} ----\"\n",
    "    start_index = content.index(search_str) + len(search_str)\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    port_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "    ports = {}\n",
    "    for line in port_section:\n",
    "        attribute, *values = line.split()\n",
    "        ports[attribute] = values\n",
    "    return ports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Region 0': {'Capacity': ['594'],\n",
       "  'Inventory': ['297'],\n",
       "  'Rate': ['99'],\n",
       "  'Price': [],\n",
       "  'BerthLimit': ['1'],\n",
       "  'PortFee': ['38'],\n",
       "  'maxAmt': ['300'],\n",
       "  'minAmt': ['35'],\n",
       "  'C2R': ['ratio', '6']},\n",
       " 'Region 1': {'Capacity': ['351', '510', '312'],\n",
       "  'Inventory': ['168', '255', '156'],\n",
       "  'Rate': ['-39', '-34', '-26'],\n",
       "  'Price': ['5', '5', '5'],\n",
       "  'BerthLimit': ['1', '1', '1'],\n",
       "  'PortFee': ['57', '58', '66'],\n",
       "  'maxAmt': ['300', '300', '259'],\n",
       "  'minAmt': ['50', '35', '20'],\n",
       "  'C2R': ['ratio', '9', '15', '12']}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract region and port information\n",
    "regions_info = parse_region_table(content)\n",
    "ports_info = {f\"Region {i}\": parse_port_table_for_region(content, i) for i in range(len(regions_info['NumPorts']))}\n",
    "ports_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ports_from_info_with_loading(ports_info):\n",
    "    all_ports = {}\n",
    "    loading_regions = {}\n",
    "    discharging_regions = {}\n",
    "\n",
    "    tot_num = 1\n",
    "    \n",
    "    for region, port_attributes in ports_info.items():\n",
    "        region_ports = []\n",
    "        is_loading_region = all(int(rate) > 0 for rate in port_attributes['Rate'])\n",
    "        is_discharging_region = all(int(rate) < 0 for rate in port_attributes['Rate'])\n",
    "\n",
    "        for i in range(len(port_attributes['Capacity'])):  # Assuming 'Capacity' is always present\n",
    "            rate = int(port_attributes['Rate'][i]) if 'Rate' in port_attributes else 0\n",
    "            isLoading = 1 if rate > 0 else -1  # Loading port if rate is positive\n",
    "\n",
    "            port = Port(\n",
    "                capacity=int(port_attributes['Capacity'][i]),\n",
    "                inventory=int(port_attributes['Inventory'][i]) if 'Inventory' in port_attributes else None,\n",
    "                rate=abs(rate),\n",
    "                price=int(port_attributes['Price'][i]) if 'Price' in port_attributes and port_attributes['Price'] else None,\n",
    "                berth_limit=int(port_attributes['BerthLimit'][i]) if 'BerthLimit' in port_attributes else None,\n",
    "                port_fee=int(port_attributes['PortFee'][i]) if 'PortFee' in port_attributes else None,\n",
    "                max_amount=int(port_attributes['maxAmt'][i]) if 'maxAmt' in port_attributes else None,\n",
    "                min_amount=int(port_attributes['minAmt'][i]) if 'minAmt' in port_attributes else None,\n",
    "                number=tot_num,  # Using 1 to numports+1 as the port number\n",
    "                isLoadingPort=isLoading)  # Determine loading port based on Rate value\n",
    "            region_ports.append(port)\n",
    "            tot_num += 1\n",
    "\n",
    "        all_ports[region] = region_ports\n",
    "\n",
    "        # Assign region to correct dictionary\n",
    "        if is_loading_region:\n",
    "            loading_regions[region] = region_ports\n",
    "        elif is_discharging_region:\n",
    "            discharging_regions[region] = region_ports\n",
    "\n",
    "    return all_ports, loading_regions, discharging_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ports, loading_regions, discharging_regions = create_ports_from_info_with_loading(ports_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 1, Port 2, Port 3, Port 4]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all ports\n",
    "ports = []\n",
    "for region, region_ports in all_ports.items():\n",
    "    ports.extend(region_ports)\n",
    "ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Port 1: Capacity = 594, Inventory = 297, Rate = 99, Price = None, Berth Limit = 1, Port Fee = 38, Max Amount = 300, Min Amount = 35, is Loading Port = 1\n",
      "Port 2: Capacity = 351, Inventory = 168, Rate = 39, Price = 5, Berth Limit = 1, Port Fee = 57, Max Amount = 300, Min Amount = 50, is Loading Port = -1\n",
      "Port 3: Capacity = 510, Inventory = 255, Rate = 34, Price = 5, Berth Limit = 1, Port Fee = 58, Max Amount = 300, Min Amount = 35, is Loading Port = -1\n",
      "Port 4: Capacity = 312, Inventory = 156, Rate = 26, Price = 5, Berth Limit = 1, Port Fee = 66, Max Amount = 259, Min Amount = 20, is Loading Port = -1\n"
     ]
    }
   ],
   "source": [
    "for port in ports:\n",
    "    print(port.__repr2__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIAL PARAMETERS\n",
    "\n",
    "All parameters should be set below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time periods\n",
    "NUM_TIME_PERIODS = 45\n",
    "metadata_from_content['numPeriods'] = NUM_TIME_PERIODS\n",
    "TIME_PERIOD_RANGE = list(range(1, NUM_TIME_PERIODS+1))\n",
    "\n",
    "# Number of vessels\n",
    "ORIGINAL_NUM_VESSELS = metadata_from_content['numTermVesselsInClass'][0]\n",
    "NUM_VESSELS = ORIGINAL_NUM_VESSELS\n",
    "\n",
    "# Speed interval\n",
    "MAX_SPEED = 15\n",
    "MIN_SPEED = 8\n",
    "OPERATING_SPEED = 14\n",
    "\n",
    "# Operating cost\n",
    "OPERATING_COST = 200\n",
    "\n",
    "# Waiting cost\n",
    "WAITING_COST = 50\n",
    "\n",
    "# Fuel price in USD per ton\n",
    "FUEL_PRICE = 500\n",
    "\n",
    "#Numper of ports\n",
    "NUM_PORTS = len(ports)\n",
    "\n",
    "EBS = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_vessel_table(content):\n",
    "    # Extract the vessel table section\n",
    "    start_index = content.index(\"----- Vessel Table ----\") + len(\"----- Vessel Table ----\")\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    vessel_section = content[start_index:end_index].strip().split(\"\\n\")[1:]  # Exclude the header line\n",
    "\n",
    "    vessels = {}\n",
    "    class_0_capacity = None\n",
    "\n",
    "    # Extract vessel attributes\n",
    "    for line in vessel_section:\n",
    "        if \"Note:\" not in line:  # Exclude the note lines\n",
    "            attribute, *values = line.split()\n",
    "            vessels[attribute] = values\n",
    "\n",
    "    # Find indices of Class 0 vessels\n",
    "    class_0_indices = [i for i, v in enumerate(vessels.get(\"Class\", [])) if v == \"0\"]\n",
    "\n",
    "    # Extract the capacity for Class 0 vessels\n",
    "    if class_0_indices:\n",
    "        class_0_capacity_index = class_0_indices[0]\n",
    "        class_0_capacity = int(vessels.get(\"Capacity\", [])[class_0_capacity_index])\n",
    "\n",
    "    return vessels, class_0_capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Type': ['Term', 'Term', 'Term', 'Term', 'Term', 'Term', 'Term'],\n",
       "  'Class': ['0', '0', '0', '0', '0', '0', '0'],\n",
       "  'Capacity': ['300', '300', '300', '300', '300', '300', '300']},\n",
       " 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the vessel dictionary and the capacity for Class 0 vessels\n",
    "vessels_info, VESSEL_CAP = parse_vessel_table(content)\n",
    "(vessels_info, VESSEL_CAP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with key = vessel class and value = vessel object\n",
    "vessels = {}\n",
    "tot = 1\n",
    "for vessel_class in range(metadata_from_content['numVesselClasses']):\n",
    "    vessel_list = []\n",
    "    vessels_in_class = metadata_from_content['numTermVesselsInClass'][vessel_class]\n",
    "    for i in range(vessels_in_class):\n",
    "        if int(vessel_data['Vessel_'+str(i)]['Initial Inventory'])>0:\n",
    "            init_inventory = VESSEL_CAP\n",
    "        else:\n",
    "            init_inventory = 0\n",
    "            \n",
    "        vessel_list.append(Vessel(\n",
    "            max_inventory= VESSEL_CAP,\n",
    "            initial_inventory= init_inventory,\n",
    "            max_operating_quantity=VESSEL_CAP,\n",
    "            number=tot\n",
    "        ))\n",
    "        tot += 1\n",
    "    vessels[vessel_class] = vessel_list\n",
    "\n",
    "# We only have one vessel class. Convert the dictionary to a list\n",
    "vessels = vessels[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 1, Vessel 2, Vessel 3, Vessel 4, Vessel 5, Vessel 6, Vessel 7]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Manually set the number of vessels\n",
    "vessels = vessels[:NUM_VESSELS]\n",
    "vessels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vessel 1: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 2: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 3: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 4: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 5: Max Inventory = 300, Inventory = 0, Max Operating Quantity = 300\n",
      "Vessel 6: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n",
      "Vessel 7: Max Inventory = 300, Inventory = 300, Max Operating Quantity = 300\n"
     ]
    }
   ],
   "source": [
    "for v in vessels:\n",
    "    print(v.__repr2__())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIXING THE ROUTES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the file from MIRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vessel_routes(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "        \n",
    "        # Find the start of the Vessel Routes section\n",
    "        start = content.find(\"Vessel Routes:\")\n",
    "        if start == -1:\n",
    "            return \"Vessel Routes section not found in the file.\"\n",
    "\n",
    "        # Extract the Vessel Routes section\n",
    "        vessel_routes_section = content[start:].split(\"\\n\", 1)[1]\n",
    "        vessel_routes_section = vessel_routes_section.split(\"\\n\\n\", 1)[0]  # Assumes there's a blank line after the section\n",
    "\n",
    "        # Process the section to create the dictionary\n",
    "        VESSEL_ROUTES = {}\n",
    "        for line in vessel_routes_section.strip().split('\\n'):\n",
    "            vessel_number, route = line.split(': ')\n",
    "            vessel_number = int(vessel_number.split(' ')[1])\n",
    "            route = eval(route)\n",
    "            VESSEL_ROUTES[vessels[vessel_number - 1]] = route\n",
    "\n",
    "        return VESSEL_ROUTES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{Vessel 3: [1, 2, 1, 2], Vessel 4: [1, 3, 1, 2], Vessel 5: [1, 3, 2, 1, 3], Vessel 6: [2, 1, 2, 1], Vessel 7: [3, 1, 3, 1]}\n"
     ]
    }
   ],
   "source": [
    "VESSEL_ROUTES = read_vessel_routes(MIRP_SOL)\n",
    "print(VESSEL_ROUTES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 1, Vessel 2]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find all vessels that are not in the solution\n",
    "vessels_to_remove = [v for v in vessels if v not in VESSEL_ROUTES]\n",
    "vessels_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Remove the vessels that are not in the solution\n",
    "# vessels = list(VESSEL_ROUTES.keys())\n",
    "# vessels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the regular nodes\n",
    "regularNodes = []\n",
    "for t in range(1, NUM_TIME_PERIODS+1):\n",
    "    for port in ports:\n",
    "        node = Node(port=port, time=t)\n",
    "        regularNodes.append(node)\n",
    "    \n",
    "# Create fictional source and sink port\n",
    "sourcePort = Port(capacity=None, inventory=None, rate=None, price=None, berth_limit=len(vessels), port_fee=0, max_amount=None, min_amount=None, number=0, isLoadingPort=True)\n",
    "sinkPort = Port(capacity=None, inventory=None, rate=None, price=None, berth_limit=len(vessels), port_fee=0, max_amount=None, min_amount=None, number=len(ports)+1, isLoadingPort=False)\n",
    "\n",
    "# Create source and sink node\n",
    "sourceNode = Node(port=sourcePort, time=0)\n",
    "sinkNode = Node(port=sinkPort, time=NUM_TIME_PERIODS+1)\n",
    "\n",
    "NODES = [sourceNode] + regularNodes + [sinkNode]\n",
    "\n",
    "# Create a node dictionary with key = (port, time) tuple and value = node object\n",
    "NODE_DICT = {}\n",
    "for node in NODES:\n",
    "    NODE_DICT[node.tuple] = node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in arc data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 5792.83, 5730.94, 5663.71],\n",
       " [5792.83, 0.0, 326.1, 338.92],\n",
       " [5730.94, 326.1, 0.0, 67.42],\n",
       " [5663.71, 338.92, 67.42, 0.0]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_full_distance_matrix(content):\n",
    "    # Extract the full distance matrix section\n",
    "    start_str = \"----- FullDistanceMatrix ----\"\n",
    "    start_index = content.index(start_str) + len(start_str)\n",
    "    end_index = content.find(\"-----\", start_index)  # Find the next section separator\n",
    "    matrix_section = content[start_index:end_index].strip().split(\"\\n\")[2:]  # Exclude the header lines\n",
    "    \n",
    "    # Convert the matrix section to a 2D list of distances\n",
    "    distances = []\n",
    "    for line in matrix_section:\n",
    "        try:\n",
    "            distance_row = list(map(float, line.split()[1:]))  # Excluding the leading port number\n",
    "            distances.append(distance_row)\n",
    "        except ValueError:\n",
    "            continue\n",
    "    \n",
    "    return distances\n",
    "\n",
    "# Extracting the full distance matrix from the file content\n",
    "full_distance_matrix = parse_full_distance_matrix(content)\n",
    "full_distance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "FULL_DISTANCE_MATRIX = full_distance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert full_distance_matrix from km to nautical miles\n",
    "# 1 nautical mile = 1.852 km\n",
    "def km_to_nautical_miles(km):\n",
    "    return km / 1.852"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_matrix_to_nautical_miles(matrix):\n",
    "    return [[km_to_nautical_miles(distance) for distance in row] for row in matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 3127.8779697624186, 3094.460043196544, 3058.158747300216],\n",
       " [3127.8779697624186, 0.0, 176.07991360691145, 183.00215982721383],\n",
       " [3094.460043196544, 176.07991360691145, 0.0, 36.40388768898488],\n",
       " [3058.158747300216, 183.00215982721383, 36.40388768898488, 0.0]]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_distance_matrix_nm = convert_matrix_to_nautical_miles(FULL_DISTANCE_MATRIX)\n",
    "full_distance_matrix_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuel_consumption_speed_nm(speed, nautical_miles):\n",
    "    \"\"\"\n",
    "    Calculate the fuel consumption based on speed and nautical miles.\n",
    "\n",
    "    Args:\n",
    "    - speed (float): Speed of the vessel in knots.\n",
    "    - nautical miles (float): .\n",
    "\n",
    "    Returns:\n",
    "    - float: Fuel consumption in tons.\n",
    "    \"\"\"\n",
    "    return  (0.15*14 * (speed / 14) ** 3) * nautical_miles/speed\n",
    "    \n",
    "\n",
    "def calc_cost(fuel_consumption):\n",
    "    \"\"\"\n",
    "    Calculate the cost based on fuel consumption.\n",
    "\n",
    "    Args:\n",
    "    - fuel_consumption (float): Fuel consumption in tons.\n",
    "\n",
    "    Returns:\n",
    "    - float: Cost in USD.\n",
    "    \"\"\"\n",
    "    return fuel_consumption * FUEL_PRICE\n",
    "\n",
    "# Function to calculate discrete max speed based on distance and global max speed\n",
    "def calculate_minimum_timesteps_and_speed(distance_nm):\n",
    "    \"\"\"\n",
    "    Determine the minimum timesteps and speed based on distance and max speed.\n",
    "\n",
    "    Args:\n",
    "    - distance_nm (float): Distance in nautical miles.\n",
    "    - MAX_SPEED (float): Maximum speed in knots.\n",
    "    - MIN_SPEED (float): Minimum speed in knots.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Minimum timesteps and speed.\n",
    "    \"\"\"\n",
    "    hours = distance_nm / MAX_SPEED\n",
    "    minimum_timesteps = math.ceil(hours / 24)\n",
    "    speed = distance_nm / (minimum_timesteps * 24)\n",
    "    return minimum_timesteps, max(speed, MIN_SPEED)\n",
    "\n",
    "# Function to calculate discrete max speed based on distance and global max speed\n",
    "def calculate_minimum_timesteps_with_fixed_speed(distance_nm):\n",
    "    \"\"\"\n",
    "    Determine the minimum timesteps and speed based on distance and operating speed.\n",
    "\n",
    "    Args:\n",
    "    - distance_nm (float): Distance in nautical miles.\n",
    "    - operating_speed (float): Operating speed in knots.\n",
    "\n",
    "    Returns:\n",
    "    - tuple: Minimum timesteps and operating speed.\n",
    "    \"\"\"\n",
    "    hours = distance_nm / OPERATING_SPEED\n",
    "    minimum_timesteps = math.ceil(hours / 24)\n",
    "    # The speed will be operating speed no matter what, but we will round up the timesteps\n",
    "    return minimum_timesteps, OPERATING_SPEED\n",
    "    \n",
    "# Based on rounded_hours and speed calculate the next speeds\n",
    "# Creates a list with all the information needed to create the arc.\n",
    "def create_arc_info(speed, minimum_timesteps, departure, origin_port, destination_port, lowest_speed, distance_to_port, vessel, is_waiting_arc):\n",
    "    # Create a list of tuples with the speed and the time period\n",
    "    '''arc_info: (speed in knots, timesteps for sailing, time period of departure, time period of arrival, origin port, destination port, fuel_consumption)'''\n",
    "    \n",
    "    arrival_time = departure + minimum_timesteps\n",
    "    if arrival_time > NUM_TIME_PERIODS:\n",
    "        return None\n",
    "    if is_waiting_arc:\n",
    "        fuel_consumption = 0\n",
    "        arc_info = [(speed, 1, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    else:\n",
    "        fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "        arc_info = [(speed, minimum_timesteps, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    \n",
    "        timesteps = minimum_timesteps+1\n",
    "        while True:\n",
    "            \n",
    "            # Calculate the next speed\n",
    "            speed = distance_to_port / ((timesteps)*24)\n",
    "            # If the speed is lower than the lowest speed, break the loop\n",
    "            if speed < lowest_speed:\n",
    "                break\n",
    "            fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "            arrival_time = departure + timesteps\n",
    "            # Otherwise, add the speed to the list\n",
    "            arc_info.append((speed, timesteps, departure, arrival_time, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc))\n",
    "            # Increment the time period\n",
    "            timesteps += 1\n",
    "            arrival_time = departure + timesteps\n",
    "            if arrival_time > NUM_TIME_PERIODS:\n",
    "                break\n",
    "       \n",
    "    return arc_info\n",
    "\n",
    "\n",
    "# Based on rounded_hours and speed calculate the next speeds\n",
    "# Creates a list with all the information needed to create the arc.\n",
    "def create_arc_info_fixed_speed(speed, minimum_timesteps, departure, arrival_time, origin_port, destination_port, distance_to_port, vessel, is_waiting_arc):\n",
    "    # Create a list of tuples with the speed and the time period\n",
    "    '''arc_info: (speed in knots, timesteps for sailing, time period of departure, time period of arrival, origin port, destination port, fuel_consumption)'''\n",
    "    \n",
    "    if arrival_time > NUM_TIME_PERIODS:\n",
    "        return None\n",
    "    if is_waiting_arc:\n",
    "        fuel_consumption = 0\n",
    "        arc_info = [(speed, 1, departure, departure + minimum_timesteps, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "    else:\n",
    "        fuel_consumption = fuel_consumption_speed_nm(speed=speed, nautical_miles=distance_to_port)\n",
    "        arc_info = [(speed, minimum_timesteps, departure, arrival_time, origin_port, destination_port, fuel_consumption, distance_to_port, vessel, is_waiting_arc)]\n",
    "       \n",
    "    return arc_info\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to have starting positions for each vessel. \n",
    "### That way we can find the earliest time a vessel can be at each port.\n",
    "\n",
    "For now we just randomly generate distances to each of the ports, without thinking about whether it is practically possible to have these distances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the arcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the information for the arcs from the source node to the ports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [Port 1]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use vessel data to find starting positions for each vessel\n",
    "# Generate the arcs\n",
    "# For the keys in discharging_regions, change the key to index of the region starting with 0\n",
    "loading_regions_reidx = {}\n",
    "\n",
    "# Reassign keys\n",
    "for i, key in enumerate(loading_regions.keys()):\n",
    "    loading_regions_reidx[i] = loading_regions[key]\n",
    "    \n",
    "loading_regions_reidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [Port 2, Port 3, Port 4]}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For the keys in discharging_regions, change the key to index of the region starting with 0\n",
    "discharging_regions_reidx = {}\n",
    "\n",
    "# Reassign keys\n",
    "for i, key in enumerate(discharging_regions.keys()):\n",
    "    discharging_regions_reidx[i] = discharging_regions[key]\n",
    "    \n",
    "discharging_regions_reidx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the information for the arcs from the source node to the ports.\n",
    "- We only get one arc for each vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_info={}\n",
    "\n",
    "def generate_source_arc_info(sourceNode):\n",
    "    \n",
    "    source_arcs_info = []\n",
    "        \n",
    "    \n",
    "    for vessel in vessels:\n",
    "        \n",
    "        initial_port_str = vessel_data['Vessel_'+str(vessel.number-1)]['Initial Port']\n",
    "        region_index, port_index = int(initial_port_str.split('_')[1]), int(initial_port_str.split('_')[3])\n",
    "        \n",
    "        # Check whether the initial port is a loading port or a discharging port based on initial_port_str\n",
    "        if initial_port_str.startswith('Loading'):\n",
    "            region_ports = loading_regions_reidx[region_index]\n",
    "            initial_port = region_ports[int(port_index)]\n",
    "        \n",
    "        else:\n",
    "            region_ports = discharging_regions_reidx[region_index]\n",
    "            initial_port = region_ports[int(port_index)]\n",
    "                \n",
    "        first_time_available = int(vessel_data['Vessel_'+str(vessel.number-1)]['First Time Available']+1)\n",
    "        \n",
    "        start_info[vessel] = NODE_DICT[(initial_port.number, first_time_available)]\n",
    "\n",
    "        \n",
    "        # Only create one arc from the source to the corresponding port and time pair\n",
    "        source_arcs_info_for_vessel = []\n",
    "        \n",
    "        speed = 0\n",
    "        \n",
    "        arc_info = [(speed, first_time_available, 0, first_time_available, sourceNode.port.number, initial_port.number, 0, 0, vessel, False)]\n",
    "        \n",
    "        source_arcs_info_for_vessel.append(arc_info)\n",
    "        \n",
    "        source_arcs_info.append(source_arcs_info_for_vessel)\n",
    "                \n",
    "    return source_arcs_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = {vessel: vessel_data['Vessel_'+str(vessel.number-1)]['First Time Available']+1 for vessel in vessels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_arcs_for_node(node, vessels, all_port_numbers, source_times, full_distance_matrix_nm):\n",
    "    node_arcs = []\n",
    "    \n",
    "    for vessel in vessels:\n",
    "        if node.port.number in [0, len(ports) + 1]:\n",
    "            continue\n",
    "\n",
    "        start_time = source_times[vessel]\n",
    "        if node.time < start_time:\n",
    "            continue\n",
    "\n",
    "        for destination_port_number in all_port_numbers:\n",
    "            if destination_port_number == node.port.number:\n",
    "                arc_info_matrix = create_arc_info(speed=0, minimum_timesteps=1, departure=node.time, origin_port=node.port.number, destination_port=destination_port_number, lowest_speed=0, distance_to_port=0, vessel=vessel, is_waiting_arc=True)\n",
    "                node_arcs.append(arc_info_matrix)\n",
    "            else:\n",
    "                distance_nm = full_distance_matrix_nm[node.port.number - 1][destination_port_number - 1]\n",
    "                minimum_timesteps, speed = calculate_minimum_timesteps_and_speed(distance_nm=distance_nm)\n",
    "                arrival_time = node.time + minimum_timesteps\n",
    "                \n",
    "                if arrival_time < source_times[vessel] or arrival_time > NUM_TIME_PERIODS:\n",
    "                    continue\n",
    "\n",
    "                arc_info_matrix = create_arc_info(speed=speed, minimum_timesteps=minimum_timesteps, departure=node.time, origin_port=node.port.number, destination_port=destination_port_number, lowest_speed=MIN_SPEED, distance_to_port=distance_nm, vessel=vessel, is_waiting_arc=False)\n",
    "                node_arcs.append(arc_info_matrix)\n",
    "\n",
    "    return node_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arcs_to_nodes(all_info):\n",
    "    arc_dict = {}\n",
    "    vessel_arcs = {}\n",
    "    waiting_arcs = {}\n",
    "\n",
    "    for sublist in all_info:\n",
    "        for subsublist in sublist:\n",
    "            if not subsublist:\n",
    "                continue\n",
    "                \n",
    "            for tuple_data in subsublist:\n",
    "                speed, timesteps, departure, arrival, origin_port_number, destination_port_number, fuel_consumption, distance_nm, vessel, is_waiting_arc = tuple_data\n",
    "                cost = calc_cost(fuel_consumption)\n",
    "                origin_node_obj = NODE_DICT.get((origin_port_number, departure))\n",
    "                destination_node_obj = NODE_DICT.get((destination_port_number, arrival))\n",
    "\n",
    "                if origin_node_obj and destination_node_obj and arrival <= NUM_TIME_PERIODS:\n",
    "                    arc = Arc(origin_node=origin_node_obj, destination_node=destination_node_obj, distance=distance_nm, cost=cost + WAITING_COST, travel_time=timesteps, speed=speed, is_waiting_arc=is_waiting_arc)\n",
    "                    origin_node_obj.outgoing_arcs.add(arc)\n",
    "                    destination_node_obj.incoming_arcs.add(arc)\n",
    "                    arc_dict[(origin_node_obj.tuple, destination_node_obj.tuple, vessel)] = arc\n",
    "                    \n",
    "                    if is_waiting_arc:\n",
    "                        waiting_arcs.setdefault(vessel, []).append(arc)\n",
    "                    vessel_arcs.setdefault(vessel, []).append(arc)\n",
    "\n",
    "    return arc_dict, vessel_arcs, waiting_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate the information for the source arcs\n",
    "# source_arcs_info = [generate_source_arc_info(vessel, [port.number for port in ports], source_distances, sourceNode) for vessel in vessels]\n",
    "\n",
    "# Generate the information for the source arcs\n",
    "source_arcs_info = generate_source_arc_info(sourceNode)\n",
    "\n",
    "# Initialize the all_info list with the source arcs info\n",
    "all_info = source_arcs_info.copy()\n",
    "\n",
    "# Append the all_info list with the arcs for each node\n",
    "for vessel in vessels:\n",
    "    # For each node, create the outgoing arcs\n",
    "    arcs_for_current_vessel = [create_arcs_for_node(node, [vessel], [port.number for port in ports], start_times, full_distance_matrix_nm) for node in NODE_DICT.values()]\n",
    "    all_info.extend(arcs_for_current_vessel)\n",
    "    \n",
    "arc_dict, vessel_arcs, waiting_arcs = add_arcs_to_nodes(all_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arc_to_dict(origin, destination, vessel, arc_dict, vessel_arcs):\n",
    "    \"\"\"Helper function to add arc to dictionaries and nodes.\"\"\"\n",
    "    arc = Arc(origin_node=origin, destination_node=destination, distance=0, cost=0, travel_time=0, speed=0, is_waiting_arc=False)\n",
    "    origin.outgoing_arcs.add(arc)\n",
    "    destination.incoming_arcs.add(arc)\n",
    "    arc_dict[(origin.tuple, destination.tuple, vessel)] = arc\n",
    "    vessel_arcs.setdefault(vessel, []).append(arc)\n",
    "    return arc_dict, vessel_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sink_arcs(vessels, sinkNode, source_times, arc_dict, vessel_arcs):\n",
    "    for vessel in vessels:\n",
    "        # Arc from source node to sink node\n",
    "        arc_dict, vessel_arcs = add_arc_to_dict(sourceNode, sinkNode, vessel, arc_dict, vessel_arcs)\n",
    "        \n",
    "        # Arcs from other nodes to sink node\n",
    "        for node in NODE_DICT.values():\n",
    "            if node.port.number not in [0, len(ports) + 1] and node.time >= source_times[vessel]:\n",
    "                arc_dict, vessel_arcs = add_arc_to_dict(node, sinkNode, vessel, arc_dict, vessel_arcs)\n",
    "    \n",
    "    return arc_dict, vessel_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After calling add_arcs_to_nodes:\n",
    "arc_dict, vessel_arcs, waiting_arcs = add_arcs_to_nodes(all_info)\n",
    "\n",
    "# Then call create_sink_arcs with the returned arc_dict and vessel_arcs:\n",
    "arc_dict, vessel_arcs = create_sink_arcs(vessels, sinkNode, start_times, arc_dict, vessel_arcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIXATE NUMBER OF VESSELS AND PORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read in the solution file and Find all port numbers\n",
    "with open(MIRP_SOL, 'r') as file:\n",
    "    content = file.read()\n",
    "    \n",
    "    # Regex pattern to find port numbers\n",
    "    pattern = r'Port (\\d+):'\n",
    "    ports_in_MIRP_SOL = re.findall(pattern, content)\n",
    "\n",
    "    # Converting port numbers to integers\n",
    "    port_numbers = [int(port) for port in ports_in_MIRP_SOL]\n",
    "    port_numbers\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "port_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 1, Port 2, Port 3, Port 4]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Port 4]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all ports that are not in the solution but in ports\n",
    "ports_to_be_removed = [port for port in ports if port.number not in port_numbers]\n",
    "ports_to_be_removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the arcs accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove all arcs from vessel_arcs that have destination port or origin port as the port to be removed\n",
    "for vessel in vessels:\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if arc.origin_node.port in ports_to_be_removed or arc.destination_node.port in ports_to_be_removed:\n",
    "            arc.origin_node.outgoing_arcs.remove(arc)\n",
    "            arc.destination_node.incoming_arcs.remove(arc)\n",
    "            del arc_dict[(arc.origin_node.tuple, arc.destination_node.tuple, vessel)]\n",
    "    vessel_arcs[vessel] = [arc for arc in vessel_arcs[vessel] if arc.origin_node.port not in ports_to_be_removed and arc.destination_node.port not in ports_to_be_removed]\n",
    "    \n",
    "    \n",
    "# Remove all arcs that have the vessel that we want to remove\n",
    "for vessel in vessels_to_remove:\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        arc.origin_node.outgoing_arcs.remove(arc)\n",
    "        arc.destination_node.incoming_arcs.remove(arc)\n",
    "        del arc_dict[(arc.origin_node.tuple, arc.destination_node.tuple, vessel)]\n",
    "    del vessel_arcs[vessel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessels = [vessel for vessel in vessels if vessel not in vessels_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Vessel 3, Vessel 4, Vessel 5, Vessel 6, Vessel 7]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all loading ports\n",
    "loading_ports = [port for port in ports if port.isLoadingPort==1]\n",
    "discharging_ports = [port for port in ports if port.isLoadingPort==-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove ports_to_be_removed from ports\n",
    "ports = [port for port in ports if port not in ports_to_be_removed]\n",
    "\n",
    "# Sum the rate for the ports that are removed\n",
    "lost_consumption = sum([port.rate for port in ports_to_be_removed])\n",
    "\n",
    "\n",
    "# Substract the lost consumption from the loading ports\n",
    "for port in loading_ports:\n",
    "    port.rate -= lost_consumption/len(loading_ports)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust the nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all the nodes for the port to be removed\n",
    "nodes_to_remove = []\n",
    "\n",
    "for node in NODES:\n",
    "    if node.port in ports_to_be_removed:\n",
    "        del NODE_DICT[node.tuple]\n",
    "        nodes_to_remove.append(node)\n",
    "        \n",
    "NODES = [node for node in NODES if node not in nodes_to_remove]\n",
    "regularNodes = [node for node in regularNodes if node not in nodes_to_remove]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the network for a given vessel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network_for_vessel(vessel, vessel_arcs, drop_sink_arcs):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node in NODES:\n",
    "        G.add_node(str(node.tuple))\n",
    "\n",
    "    # Add edges (arcs) to the graph\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        # If the arc goes to the sink node, skip it\n",
    "        if drop_sink_arcs and arc.destination_node == sinkNode:\n",
    "            continue\n",
    "        G.add_edge(str(arc.origin_node.tuple), str(arc.destination_node.tuple))\n",
    "\n",
    "    # Determine NODES with incoming and outgoing arcs\n",
    "    nodes_with_incoming_arcs = [node for node, degree in G.in_degree() if degree > 0]\n",
    "    nodes_with_outgoing_arcs = [node for node, degree in G.out_degree() if degree > 0]\n",
    "\n",
    "    # Create a list to hold node colors\n",
    "    node_colors = []\n",
    "    for node in G.nodes():\n",
    "        if node in nodes_with_incoming_arcs or node in nodes_with_outgoing_arcs:\n",
    "            node_colors.append('green')  # Color for nodes with arcs\n",
    "        else:\n",
    "            node_colors.append('skyblue')  # Default color\n",
    "\n",
    "    # Resetting the y_offset and y_spacing\n",
    "    y_offset = 10\n",
    "    y_spacing = -30  # Increase vertical spacing for better clarity\n",
    "\n",
    "    # Manually specify the positions for each node\n",
    "    pos = {}\n",
    "\n",
    "    # Manually set the position for the source and sink nodes\n",
    "    # pos[\"(0, 0)\"] = (0, 0)  # Positioning source node at leftmost, middle height\n",
    "    # pos[\"(5, 5)\"] = (5 * 10, 0)  # Positioning sink node at rightmost, middle height\n",
    "\n",
    "    for node in NODES:\n",
    "        # Skip setting position for source and sink nodes\n",
    "        # if str(node.tuple) in [\"(0, 0)\", \"(5, 5)\"]:\n",
    "        #     continue\n",
    "        port_index = node.port.number  # Get port number to determine y-coordinate\n",
    "        # The x-coordinate is based on time, the y-coordinate is fixed for nodes with the same port\n",
    "        pos[str(node.tuple)] = (node.time * 10, port_index * y_spacing)  # Multiplying time by 10 for better horizontal spacing\n",
    "\n",
    "    # Drawing the graph using the adjusted positions\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=10)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    plt.title(\"Nodes and Arcs Graph\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vessel in vessels:\n",
    "#     visualize_network_for_vessel(vessel, vessel_arcs, drop_sink_arcs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def filter_arcs_for_equal_speed_spread(arcs):\n",
    "    if len(arcs) <= 4:\n",
    "        return arcs\n",
    "\n",
    "    # Sort arcs by speed\n",
    "    sorted_arcs = sorted(arcs, key=lambda arc: arc.speed)\n",
    "\n",
    "    slowest_arc = sorted_arcs[0]\n",
    "    fastest_arc = sorted_arcs[-1]\n",
    "\n",
    "    # To equally spread the speeds, we'll try to minimize the variance of the differences in speeds\n",
    "    # between consecutive selected arcs.\n",
    "    min_variance = float('inf')\n",
    "    selected_arcs = [slowest_arc, fastest_arc]\n",
    "\n",
    "    for i in range(1, len(sorted_arcs) - 2):\n",
    "        for j in range(i + 1, len(sorted_arcs) - 1):\n",
    "            speeds = [slowest_arc.speed, sorted_arcs[i].speed, sorted_arcs[j].speed, fastest_arc.speed]\n",
    "            intervals = [speeds[k + 1] - speeds[k] for k in range(len(speeds) - 1)]\n",
    "            variance = sum((x - sum(intervals) / len(intervals)) ** 2 for x in intervals) / len(intervals)\n",
    "\n",
    "            if variance < min_variance:\n",
    "                min_variance = variance\n",
    "                selected_arcs = [slowest_arc, sorted_arcs[i], sorted_arcs[j], fastest_arc]\n",
    "\n",
    "    return selected_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FA:\n",
    "    filtered_arcs = {}\n",
    "    for vessel in vessels:\n",
    "        arcs = vessel_arcs[vessel]\n",
    "\n",
    "        # Group arcs by (origin node, destination port)\n",
    "        grouped_arcs = defaultdict(list)\n",
    "        for arc in arcs:\n",
    "            origin_node = arc.origin_node\n",
    "            destination_port = arc.destination_node.port\n",
    "            grouped_arcs[(origin_node, destination_port)].append(arc)\n",
    "\n",
    "        # Filter arcs in each group\n",
    "        filtered_arcs_for_v = []\n",
    "\n",
    "        # print(grouped_arcs[NODE_DICT[(3, 5)], ports[0]])\n",
    "        for group in grouped_arcs:\n",
    "            filtered_arcs_for_v.extend(filter_arcs_for_equal_speed_spread(grouped_arcs[group]))\n",
    "        \n",
    "        filtered_arcs[vessel] = filtered_arcs_for_v\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_earliest_visits_from_start(filtered_arcs, start_node):\n",
    "    # Dictionary to store the earliest visit time for each port\n",
    "    earliest_visits = {}\n",
    "\n",
    "    # Filter arcs to include only those originating from the start node\n",
    "    outgoing_arcs = [arc for arc in filtered_arcs if arc.origin_node == start_node]\n",
    "\n",
    "    # Iterate through the outgoing arcs\n",
    "    for arc in outgoing_arcs:\n",
    "        dest_port = arc.destination_node.port\n",
    "        dest_time = arc.destination_node.time\n",
    "\n",
    "        # Update the earliest visit time for each destination port\n",
    "        if dest_port not in earliest_visits or dest_time < earliest_visits[dest_port]:\n",
    "            earliest_visits[dest_port] = dest_time\n",
    "\n",
    "    return earliest_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_visits = {}\n",
    "for vessel in vessels:\n",
    "    if FA:\n",
    "        earliest_visits[vessel] = find_earliest_visits_from_start(filtered_arcs[vessel], start_info[vessel])\n",
    "    else:\n",
    "        earliest_visits[vessel] = find_earliest_visits_from_start(vessel_arcs[vessel], start_info[vessel])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 3: {Port 1: 2, Port 2: 10, Port 3: 10, Port 5: 46},\n",
       " Vessel 4: {Port 1: 7, Port 2: 15, Port 3: 15, Port 5: 46},\n",
       " Vessel 5: {Port 1: 4, Port 2: 12, Port 3: 12, Port 5: 46},\n",
       " Vessel 6: {Port 1: 11, Port 2: 3, Port 3: 3, Port 5: 46},\n",
       " Vessel 7: {Port 1: 14, Port 2: 6, Port 3: 6, Port 5: 46}}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earliest_visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FA:\n",
    "    filtered = filtered_arcs.copy()\n",
    "else:\n",
    "    filtered = vessel_arcs.copy()\n",
    "\n",
    "for v in vessels:\n",
    "    # Create a new list for storing filtered arcs\n",
    "    new_filtered_arcs = []\n",
    "\n",
    "    for arc in filtered[v]:\n",
    "        # Skip the source and sink nodes\n",
    "        # if arc.origin_node == sourceNode or arc.destination_node == sinkNode:\n",
    "        if arc.origin_node == sourceNode:\n",
    "            new_filtered_arcs.append(arc)\n",
    "            continue\n",
    "        \n",
    "        if arc.origin_node == start_info[v]:\n",
    "            new_filtered_arcs.append(arc)\n",
    "            continue\n",
    "\n",
    "        # Check the earliest visit time constraints\n",
    "        if arc.origin_node.time >= earliest_visits[v][arc.origin_node.port] \\\n",
    "           and arc.destination_node.time >= earliest_visits[v][arc.destination_node.port]:\n",
    "            new_filtered_arcs.append(arc)\n",
    "    filtered[v] = new_filtered_arcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of arcs before filtering: 6505\n",
      "Total number of arcs after filtering: 5565\n"
     ]
    }
   ],
   "source": [
    "total_vessel_arcs = sum(len(vessel_arcs[v]) for v in vessels)\n",
    "total_filtered_arcs = sum(len(filtered[v]) for v in vessels)\n",
    "\n",
    "# Print the total number of arcs for each vessel before and after filtering\n",
    "print(f\"Total number of arcs before filtering: {total_vessel_arcs}\")\n",
    "print(f\"Total number of arcs after filtering: {total_filtered_arcs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "vessel_arcs = filtered.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the count of visits for each port for each vessel\n",
    "visit_count = {v: {p.number: 0 for p in ports} for v in vessels}\n",
    "\n",
    "# Update the visit count according to the vessel routes\n",
    "for v, route in VESSEL_ROUTES.items():\n",
    "    for p in route:\n",
    "        visit_count[v][p] += 1\n",
    "        \n",
    "all_o_indices = []\n",
    "for v in vessels:\n",
    "    for p in ports:\n",
    "        for t in TIME_PERIOD_RANGE:\n",
    "            for visit in range(1, visit_count[v][p.number] + 1):\n",
    "                index = (p.number, t, v, visit)\n",
    "                all_o_indices.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each o_index in all_o_indices, find the corresponding index for the q_index\n",
    "all_q_indices = []\n",
    "for o_index in all_o_indices:\n",
    "    p, t, v, _ = o_index\n",
    "    q_index = (p, t, v)\n",
    "    all_q_indices.append(q_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_network_for_vessel(v, vessel_arcs, drop_sink_arcs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting with Gurobi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Creating the variables'''\n",
    "'''Binary first'''\n",
    "# x is the binary variable that indicates whether a vessel travels on arc a, where and arc is a route frome one node to another node.\n",
    "x = m.addVars(((arc.tuple, vessel) for vessel in vessels for arc in vessel_arcs[vessel]) , vtype=gp.GRB.BINARY, name=\"x\")\n",
    "\n",
    "# Create o variables only for the number of visits that actually occur for each port for each vessel\n",
    "o = m.addVars((index for index in all_o_indices), vtype=gp.GRB.BINARY, name=\"o\") \n",
    "\n",
    "'''Continuous varibles'''\n",
    "# q is the amount of product loaded or unloaded at port i by vessel v at time t\n",
    "q_bounds = {(node.port.number, node.time, vessel): min(vessel.max_inventory, node.port.capacity) for node in regularNodes for vessel in vessels}\n",
    "q = m.addVars(q_bounds.keys(), lb=0, ub=q_bounds, vtype=gp.GRB.CONTINUOUS, name=\"q\")\n",
    "\n",
    "# s is the amount of product at port i at the end of period t\n",
    "s_bounds = {(node.port.number, node.time): node.port.capacity for node in regularNodes}\n",
    "s = m.addVars(s_bounds.keys(), lb=0, ub=s_bounds, vtype=gp.GRB.CONTINUOUS, name=\"s\")\n",
    "\n",
    "# Create s vars for each port in time period 0\n",
    "s_bounds_source = {(port.number, 0): port.capacity for port in ports}\n",
    "s_source = m.addVars(s_bounds_source.keys(), lb=0, ub=s_bounds, vtype=gp.GRB.CONTINUOUS, name=\"s\")\n",
    "s.update(s_source)\n",
    "\n",
    "# w is the amount of product on board of vessel v at the end of time period t\n",
    "w_bounds = {(t, vessel): vessel.max_inventory for vessel in vessels for t in TIME_PERIOD_RANGE}\n",
    "w = m.addVars(w_bounds.keys(), lb=0, ub=w_bounds, vtype=gp.GRB.CONTINUOUS, name=\"w\")\n",
    "w_bounds_source = {(0, vessel): vessel.max_inventory for vessel in vessels}\n",
    "w_source = m.addVars(w_bounds_source.keys(), lb=0, ub=w_bounds, vtype=gp.GRB.CONTINUOUS, name=\"w\")\n",
    "w.update(w_source)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5565, 945, 675, 138, 230)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x), len(o), len(q), len(s), len(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict where the arc.tuple is the key and arc.cost is the value\n",
    "\n",
    "costs = {(arc.tuple, vessel): arc.cost for vessel in vessels for arc in vessel_arcs[vessel] }\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obj = gp.quicksum(costs[key]*x[key] for key in costs) + gp.quicksum(o[node.port.number, node.time, vessel] * 50 for node in regularNodes for vessel in vessels)\n",
    "\n",
    "obj = gp.quicksum(costs[key] * x[key] for key in costs) + gp.quicksum(o[index] * OPERATING_COST for index in all_o_indices)\n",
    "\n",
    "\n",
    "#Minimize the costs\n",
    "m.setObjective(obj, GRB.MINIMIZE)\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (2)\n",
    "for v in vessels:\n",
    "    outgoing_from_source = [arc for arc in vessel_arcs[v] if arc.origin_node == sourceNode]\n",
    "    m.addConstr(gp.quicksum((x[arc.tuple, v]) for arc in outgoing_from_source) == 1, name = 'SourceFlow')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (3)\n",
    "for v in vessels:\n",
    "    incoming_to_sink = [arc for arc in vessel_arcs[v] if arc.destination_node == sinkNode]\n",
    "    m.addConstr(gp.quicksum((x[arc.tuple, v]) for arc in incoming_to_sink) == 1, name = 'SinkFlow')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (4)\n",
    "# Creating a flow balance constraint for each node\n",
    "\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        outgoing_from_node = [arc for arc in vessel_arcs[v] if arc.origin_node == node]\n",
    "        incoming_to_node = [arc for arc in vessel_arcs[v] if arc.destination_node == node]\n",
    "        m.addConstr(gp.quicksum((x[in_arc.tuple, v]) for in_arc in incoming_to_node) - gp.quicksum((x[out_arc.tuple, v]) for out_arc in outgoing_from_node) == 0, name = \"FlowBalance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (5)\n",
    "for port in ports:\n",
    "    m.addConstr(s_source[port.number, 0] == port.inventory, name = 'InitialInventoryPort')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (6)\n",
    "'''Rate is static for now'''\n",
    "# Inventory balance for ports at the end of each time period t\n",
    "for port in ports:\n",
    "    for t in TIME_PERIOD_RANGE:\n",
    "        m.addConstr(s[port.number, t] == (s[port.number, t-1] + (port.isLoadingPort * port.rate) - gp.quicksum(port.isLoadingPort * q[port.number, t, v] for v in vessels)) , name = 'InventoryBalance')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (7)\n",
    "\n",
    "for v in vessels:\n",
    "    m.addConstr(w_source[0, v] == v.inventory, name = 'InitialInventoryVessel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (8)\n",
    "\n",
    "# for each vessel, the inventory at the end of the time period is equal to the inventory at the beginning of the time period + the amount of product loaded/unloaded at the ports\n",
    "for t in TIME_PERIOD_RANGE:\n",
    "    for v in vessels:\n",
    "        m.addConstr(w[t, v] == gp.quicksum(port.isLoadingPort * q[port.number, t, v] for port in ports) + w[t-1,v], name = 'VesselBalance')\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (9): Berth limit at each port in each time period\n",
    "for node in regularNodes:\n",
    "    for v in vessels:\n",
    "        # Find indices for o variables for the current vessel and port\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        m.addConstr((gp.quicksum(o[index] \n",
    "                                for index in o_indices ) \n",
    "                    <= node.port.berth_limit), \n",
    "                    name = f'Berth_limit_port_{node.port.number}_time_{node.time}')\n",
    "m.update()\n",
    "\n",
    "'''ER IKKE DENNE FEIL? BØR VEL SUMMERE OVER ALLE VESSELS?'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Constraint (10)\n",
    "\n",
    "for index in all_o_indices:\n",
    "    port_number, time, vessel, visit = index\n",
    "    node = NODE_DICT[(port_number, time)]\n",
    "    incoming_to_node = [arc for arc in vessel_arcs[vessel] if arc.destination_node == node]\n",
    "    m.addConstr(o[index] <= gp.quicksum((x[in_arc.tuple, vessel]) for in_arc in incoming_to_node), name = f'Operate_vessel_{vessel}_node_{node.port.number}_time_{node.time}_visit_{visit}')\n",
    "    \n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict with all waiting arcs with key = (arc.tuple, v)\n",
    "# (node.port.number, node.time), (node.port.number, node.time + 1)\n",
    "all_waiting_arcs = {}\n",
    "for v in vessels:\n",
    "    for arc in waiting_arcs[v]:\n",
    "        origin_node = arc.origin_node\n",
    "        destination_node = arc.destination_node\n",
    "        all_waiting_arcs[((origin_node.port.number, origin_node.time),(destination_node.port.number, destination_node.time) , v)] = arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (11)\n",
    "                \n",
    "for index in all_o_indices:\n",
    "    port_number, time, vessel, visit = index\n",
    "    node = NODE_DICT[(port_number, time)]\n",
    "    if (node.port.number, node.time + 1, vessel, visit + 1) in o.keys():  # check if o for the next period and next visit exists\n",
    "        waiting_arc_key = ((node.port.number, node.time), (node.port.number, node.time + 1), vessel)\n",
    "        if waiting_arc_key in all_waiting_arcs.keys():\n",
    "            waiting_arc = all_waiting_arcs[waiting_arc_key]\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        actual_key = (waiting_arc.tuple, vessel)\n",
    "        \n",
    "        if actual_key in x.keys():  # check if the waiting arc exists\n",
    "            m.addConstr(o[index] <= \n",
    "                        o[(node.port.number, node.time + 1, vessel, visit + 1)] + \n",
    "                        (1 - x[actual_key]),\n",
    "                        name=f\"Operate_or_Move_{node.port.number}_{node.time}_{vessel}_visit_{visit}\")\n",
    "\n",
    "m.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Constraint (12): The quantity of product loaded or unloaded must not exceed the maximum operating quantity for each operation\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        # Find o-indices for the current node and vessel\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        m.addConstr(q[node.port.number, node.time, v] <= gp.quicksum(o[index] for index in o_indices) * v.max_operating_quantity,\n",
    "                    name=f'Max_operating_quantity_vessel_{v}_port_{node.port.number}_time_{node.time}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Constraint 13\n",
    "        \n",
    "# Constraint 14: Each vessel can perform at most one operation per time period across all ports and visits\n",
    "for v in vessels:\n",
    "    for t in TIME_PERIOD_RANGE:\n",
    "        # Find the set of all o-indices for the current vessel and node\n",
    "        o_indices = [index for index in all_o_indices if index[1] == t and index[2] == v]\n",
    "        m.addConstr(gp.quicksum(o[index] for index in o_indices) <= 1,\n",
    "                    name=f'Only_one_operation_per_time_period_vessel_{v}_time_{t}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "# Constraint 14: Each vessel must complete its sequence by performing an operation at the last port in its sequence\n",
    "for v in vessels:\n",
    "    if VESSEL_ROUTES[v]:\n",
    "        last_port_in_sequence = VESSEL_ROUTES[v][-1]\n",
    "        last_visit_count = VESSEL_ROUTES[v].count(last_port_in_sequence)\n",
    "        m.addConstr(gp.quicksum(o[last_port_in_sequence, t, v, last_visit_count] for t in TIME_PERIOD_RANGE) >= 1,\n",
    "                    name=f'Sequence_completion_constraint_vessel_{v}')\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint 15: Limit the number of operations at each port for each vessel as per visit_count\n",
    "for v in vessels:\n",
    "    for p in ports:\n",
    "        # visit_count[v][p.number] gives the allowed number of visits to port p for vessel v\n",
    "        allowed_visits = visit_count[v][p.number]\n",
    "\n",
    "        # Sum over all time periods and all visits (up to allowed_visits) should not exceed allowed_visits\n",
    "        m.addConstr(\n",
    "            gp.quicksum(o[p.number, t, v, visit] for t in TIME_PERIOD_RANGE for visit in range(1, allowed_visits + 1)) <= allowed_visits,\n",
    "            name=f'Operation_limit_vessel_{v}_port_{p.number}'\n",
    "        )\n",
    "m.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Enforcing the correct sequence of operations\n",
    "for v in vessels:\n",
    "    sequence = VESSEL_ROUTES[v]\n",
    "    visit_counts = {port: 0 for port in sequence}\n",
    "    \n",
    "    for i in range(1, len(sequence)):\n",
    "        this_port = sequence[i-1]\n",
    "        next_port = sequence[i]\n",
    "        visit_counts[this_port] += 1\n",
    "        this_visit = visit_counts[this_port]\n",
    "        next_visit = visit_counts[next_port] + 1\n",
    "        \n",
    "        # For each time period, ensure the operation at next_port follows the operation at this_port\n",
    "        for t in TIME_PERIOD_RANGE:\n",
    "            # Sum of operations at this_port for all time periods up to t-1 must be greater than or equal to\n",
    "            # the sum of operations at next_port for all time periods up to t\n",
    "            m.addConstr(\n",
    "                gp.quicksum(o[this_port, t_prime, v, this_visit] for t_prime in TIME_PERIOD_RANGE if t_prime < t) >=\n",
    "                gp.quicksum(o[next_port, t_prime, v, next_visit] for t_prime in TIME_PERIOD_RANGE if t_prime <= t),\n",
    "                name=f'Sequence_{v}_this_{this_port}_{this_visit}_next_{next_port}_{next_visit}_time_{t}'\n",
    "            )\n",
    "m.update()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constraint (17) modification\n",
    "# Ensure that q is at least 1/4 of the vessel's capacity if o is 1\n",
    "\n",
    "for v in vessels:\n",
    "    for node in regularNodes:\n",
    "        o_indices = [index for index in all_o_indices if index[0] == node.port.number and index[1] == node.time and index[2] == v]\n",
    "        for index in o_indices:\n",
    "            m.addConstr(q[node.port.number, node.time, v] >= 1/4 * v.max_inventory * o[index], name=f'q_{node.port.number}_{node.time}_{v}_visit_{visit}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 10.0.3 build v10.0.3rc0 (mac64[x86])\n",
      "\n",
      "CPU model: Intel(R) Core(TM) i5-8257U CPU @ 1.40GHz\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "\n",
      "Optimize a model with 5599 rows, 7553 columns and 61606 nonzeros\n",
      "Model fingerprint: 0x956af637\n",
      "Variable types: 1043 continuous, 6510 integer (6510 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e+00, 3e+02]\n",
      "  Objective range  [5e+01, 3e+05]\n",
      "  Bounds range     [1e+00, 6e+02]\n",
      "  RHS range        [1e+00, 3e+02]\n",
      "Presolve removed 2244 rows and 1012 columns\n",
      "Presolve time: 0.41s\n",
      "Presolved: 3355 rows, 6541 columns, 51759 nonzeros\n",
      "Variable types: 713 continuous, 5828 integer (5827 binary)\n",
      "\n",
      "Root relaxation: objective 7.223224e+04, 3224 iterations, 0.22 seconds (0.29 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 72232.2371    0  823          - 72232.2371      -     -    0s\n",
      "     0     0 72234.7392    0  817          - 72234.7392      -     -    0s\n",
      "     0     0 72260.8330    0  798          - 72260.8330      -     -    1s\n",
      "     0     0 221537.703    0  651          - 221537.703      -     -    2s\n",
      "     0     0 221537.703    0  643          - 221537.703      -     -    2s\n",
      "     0     0 223458.338    0  644          - 223458.338      -     -    2s\n",
      "     0     0 223458.338    0  643          - 223458.338      -     -    2s\n",
      "     0     0 223458.338    0  647          - 223458.338      -     -    2s\n",
      "     0     0 223458.338    0  646          - 223458.338      -     -    2s\n",
      "     0     0 304275.831    0  571          - 304275.831      -     -    2s\n",
      "     0     0 304567.434    0  545          - 304567.434      -     -    2s\n",
      "     0     0 304572.363    0  535          - 304572.363      -     -    2s\n",
      "     0     0 310104.571    0  617          - 310104.571      -     -    3s\n",
      "     0     0 310112.058    0  598          - 310112.058      -     -    3s\n",
      "     0     0 328016.222    0  622          - 328016.222      -     -    3s\n",
      "     0     0 328054.103    0  611          - 328054.103      -     -    4s\n",
      "     0     0 341034.391    0  709          - 341034.391      -     -    4s\n",
      "     0     0 342705.521    0  672          - 342705.521      -     -    4s\n",
      "     0     0 342725.209    0  650          - 342725.209      -     -    4s\n",
      "     0     0 342901.346    0  711          - 342901.346      -     -    5s\n",
      "     0     0 343058.821    0  688          - 343058.821      -     -    5s\n",
      "     0     0 343079.365    0  693          - 343079.365      -     -    5s\n",
      "     0     0 343500.478    0  691          - 343500.478      -     -    5s\n",
      "     0     0 343833.699    0  686          - 343833.699      -     -    5s\n",
      "     0     0 343860.189    0  689          - 343860.189      -     -    5s\n",
      "     0     0 343937.963    0  699          - 343937.963      -     -    6s\n",
      "     0     0 343937.963    0  662          - 343937.963      -     -    6s\n",
      "     0     2 367240.936    0  674          - 367240.936      -     -    8s\n",
      "    19    20 379350.726    6  716          - 379350.726      -  1122   10s\n",
      "   181   178 529042.699   41  610          - 383748.577      -   602   15s\n",
      "   766   752 782662.040  204  434          - 383748.577      -   264   20s\n",
      "  1404  1373 1343073.62  377  357          - 383748.577      -   244   25s\n",
      "  1712  1585 867365.293   29  675          - 383748.577      -   224   30s\n",
      "  1730  1597 1011838.34  102  522          - 1011838.34      -   222   35s\n",
      "H 1743  1525                    3275434.1657 1067701.11  67.4%   220   39s\n",
      "H 1743  1448                    3275284.1657 1067701.11  67.4%   220   39s\n",
      "H 1743  1375                    3264292.8053 1067701.11  67.3%   220   39s\n",
      "H 1743  1306                    2960918.1574 1071576.67  63.8%   220   39s\n",
      "  1746  1308 1072536.98   63  519 2960918.16 1072536.98  63.8%   220   40s\n",
      "H 1751  1244                    2960868.1574 1083171.47  63.4%   219   42s\n",
      "H 1753  1182                    2914543.2611 1083832.10  62.8%   219   43s\n",
      "H 1756  1124                    2878117.5321 1085460.50  62.3%   218   43s\n",
      "H 1757  1068                    2857845.3434 1085460.50  62.0%   218   44s\n",
      "H 1757  1014                    2857695.3434 1085460.50  62.0%   218   44s\n",
      "H 1757   962                    2857645.3434 1085460.50  62.0%   218   44s\n",
      "H 1757   913                    2857495.3434 1085460.50  62.0%   218   44s\n",
      "  1759   914 1087629.59  242  600 2857495.34 1087629.59  61.9%   218   45s\n",
      "H 1759   868                    2759943.6090 1087629.59  60.6%   218   45s\n",
      "H 1761   825                    2745545.0101 1090272.41  60.3%   218   46s\n",
      "H 1767   787                    2739782.5219 1099034.60  59.9%   217   48s\n",
      "H 1767   747                    2704548.9860 1099178.57  59.4%   217   49s\n",
      "  1774   752 1441620.45  285  604 2704548.99 1099318.11  59.4%   240   50s\n",
      "H 1778   717                    2674340.0474 1112609.15  58.4%   240   52s\n",
      "  1787   723 1150422.25   71  649 2674340.05 1150422.25  57.0%   239   55s\n",
      "  1799   731 1171443.22    8  600 2674340.05 1171443.22  56.2%   237   60s\n",
      "  1820   741 1259987.15   29  504 2674340.05 1225264.21  54.2%   258   65s\n",
      "  1965   786 1410902.22   44  347 2674340.05 1280691.33  52.1%   272   70s\n",
      "H 2021   750                    2674340.0245 1280691.33  52.1%   271   71s\n",
      "  2123   777 1962322.46   59  319 2674340.02 1280691.33  52.1%   280   75s\n",
      "  2476   882 2232107.10   99  195 2674340.02 1280691.33  52.1%   266   80s\n",
      "H 2493   841                    2662626.6319 1280691.33  51.9%   265   80s\n",
      "  2672   837 1464040.02   33  375 2662626.63 1339764.36  49.7%   259   85s\n",
      "H 2678   802                    2657526.4048 1339764.36  49.6%   259   85s\n",
      "H 2731   802                    2657476.4048 1354569.89  49.0%   257   87s\n",
      "  2858   884 1823031.69   62  292 2657476.40 1354569.89  49.0%   251   90s\n",
      "  3360  1060 1854973.04   35  278 2657476.40 1379820.77  48.1%   226   95s\n",
      "H 3738  1192                    2657476.1431 1397960.51  47.4%   216  100s\n",
      "  4173  1533 1988920.52   39  322 2657476.14 1435599.52  46.0%   207  106s\n",
      "H 4801  1893                    2657476.1327 1473523.00  44.6%   194  110s\n",
      "  5719  2455 1943416.32   47  279 2657476.13 1545520.08  41.8%   182  116s\n",
      "H 6118  2543                    2657476.1305 1553595.92  41.5%   177  118s\n",
      "  6231  2646 2165588.88   30  264 2657476.13 1564156.06  41.1%   177  120s\n",
      "  7062  3152 infeasible  145      2657476.13 1591836.70  40.1%   169  125s\n",
      "  7647  3578 2517748.94   85  130 2657476.13 1606907.75  39.5%   164  131s\n",
      "  9110  4364 infeasible   33      2657476.13 1641217.90  38.2%   151  137s\n",
      "* 9889  4634             129    2620367.7828 1655882.18  36.8%   146  139s\n",
      " 10019  4928 2056913.39   76  226 2620367.78 1662768.33  36.5%   145  141s\n",
      "H10570  4768                    2593482.2091 1669450.69  35.6%   142  142s\n",
      " 10574  4771 2197445.47   78  399 2593482.21 1669450.69  35.6%   141  145s\n",
      "H10588  4540                    2524034.9647 1669450.69  33.9%   141  148s\n",
      " 10597  4546 2524034.96   89  525 2524034.96 1669450.69  33.9%   141  150s\n",
      "H10608  4326                    2523984.9647 1669450.69  33.9%   141  152s\n",
      "H10618  4114                    2515537.5694 1669450.69  33.6%   141  155s\n",
      " 10640  4129 2515537.57   63  520 2515537.57 1763397.63  29.9%   141  160s\n",
      "H10658  3933                    2481323.3682 1790626.34  27.8%   140  164s\n",
      " 10662  3936 1814390.59   44  576 2481323.37 1814390.59  26.9%   140  165s\n",
      " 10683  3950 2383726.11   81  596 2481323.37 1836133.49  26.0%   140  170s\n",
      " 10703  3963 2390450.74   67  580 2481323.37 1850707.75  25.4%   140  175s\n",
      " 10722  3976 2419053.93   52  558 2481323.37 1871272.51  24.6%   140  180s\n",
      " 10734  3984 2378437.28   79  605 2481323.37 1877326.69  24.3%   139  185s\n",
      " 10789  4007 infeasible   44      2481323.37 1895420.39  23.6%   145  190s\n",
      " 10914  4014 1992471.15   58  436 2481323.37 1895420.39  23.6%   145  195s\n",
      " 11114  4001 2075148.25   58  288 2481323.37 1950507.61  21.4%   145  200s\n",
      " 11312  3997 2032418.66   44  359 2481323.37 1967866.56  20.7%   144  205s\n",
      " 11525  3982 2381123.59   62  234 2481323.37 1971759.34  20.5%   143  210s\n",
      " 11759  3962 2454436.45   64  137 2481323.37 2039194.73  17.8%   142  215s\n",
      " 12101  3980 2257785.64   96  213 2481323.37 2054075.35  17.2%   140  220s\n",
      " 13014  4145 2357293.19   86  165 2481323.37 2119385.78  14.6%   137  226s\n",
      " 14195  4221     cutoff   72      2481323.37 2165788.87  12.7%   132  230s\n",
      "H14525  3966                    2471384.3791 2173792.10  12.0%   131  232s\n",
      " 15451  3919 2322036.05   56  359 2471384.38 2203808.55  10.8%   127  236s\n",
      " 16445  3683 2428446.78   58  266 2471384.38 2233873.64  9.61%   125  240s\n",
      " 17463  3268     cutoff   58      2471384.38 2279493.09  7.76%   124  245s\n",
      " 18773  2335 infeasible   59      2471384.38 2329943.64  5.72%   122  250s\n",
      " 20472  1011 infeasible   65      2471384.38 2398750.18  2.94%   118  256s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 1\n",
      "  Gomory: 20\n",
      "  Cover: 50\n",
      "  Implied bound: 4\n",
      "  Clique: 8\n",
      "  MIR: 37\n",
      "  StrongCG: 2\n",
      "  Flow cover: 121\n",
      "  Flow path: 19\n",
      "  Inf proof: 15\n",
      "  Zero half: 146\n",
      "  Mod-K: 1\n",
      "  RLT: 12\n",
      "  Relax-and-lift: 5\n",
      "\n",
      "Explored 21544 nodes (2497318 simplex iterations) in 257.05 seconds (285.23 work units)\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 10: 2.47138e+06 2.48132e+06 2.51554e+06 ... 2.65753e+06\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.471384379062e+06, best bound 2.471384379062e+06, gap 0.0000%\n",
      "Optimal solution found!\n"
     ]
    }
   ],
   "source": [
    "#optimize the model\n",
    "# Assuming you have a Gurobi model object named 'model' and a variable named 'arc_vars' representing the arcs\n",
    "\n",
    "# Possibility of setting a time limit\n",
    "# m.setParam(gp.GRB.Param.TimeLimit, 30)\n",
    "\n",
    "# Optimize the model\n",
    "m.optimize()\n",
    "\n",
    "# Check the status of the optimization\n",
    "if m.status == gp.GRB.OPTIMAL:\n",
    "    print(\"Optimal solution found!\")\n",
    "    \n",
    "# If the model is infeasible, compute the IIS\n",
    "if m.status == gp.GRB.INFEASIBLE:\n",
    "    print('Model is infeasible')\n",
    "    m.computeIIS()\n",
    "    # Write the IIS to a .ilp file\n",
    "    m.write(\"model.ilp\")\n",
    "    print('The infeasibility is written to the file \"model.ilp\"')\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective value: 2471384.3790619285\n"
     ]
    }
   ],
   "source": [
    "print(f'Objective value: {m.objVal}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each vessel, save the route\n",
    "vessel_routes_incl_wa = {}\n",
    "for vessel in vessels:\n",
    "    vessel_routes_incl_wa[vessel] = []\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if x[arc.tuple, vessel].x > 0:\n",
    "            vessel_routes_incl_wa[vessel].append(arc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arcs in each route by time\n",
    "for vessel in vessels:\n",
    "    vessel_routes_incl_wa[vessel] = sorted(vessel_routes_incl_wa[vessel], key=lambda x: x.origin_node.time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 3: [1, 2, 1, 2],\n",
       " Vessel 4: [1, 3, 1, 2],\n",
       " Vessel 5: [1, 3, 2, 1, 3],\n",
       " Vessel 6: [2, 1, 2, 1],\n",
       " Vessel 7: [3, 1, 3, 1]}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VESSEL_ROUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0) -> (1, 1) --- Cost: 50 --- Speed: 0,\n",
       " (1, 1) -> (2, 12) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       " (2, 12) -> (1, 23) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       " (1, 23) -> (2, 33) --- Cost: 203347.53480831845 --- Speed: 13.032824874010078,\n",
       " (2, 33) -> (5, 46) --- Cost: 0 --- Speed: 0]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "vessel_routes_incl_wa[vessels[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 3: [(0, 0) -> (1, 1) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 1) -> (2, 12) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (2, 12) -> (1, 23) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (1, 23) -> (2, 33) --- Cost: 203347.53480831845 --- Speed: 13.032824874010078,\n",
       "  (2, 33) -> (5, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 4: [(0, 0) -> (1, 6) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 6) -> (1, 7) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 7) -> (1, 8) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 8) -> (1, 9) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 9) -> (3, 20) --- Cost: 162736.67240491294 --- Speed: 11.721439557562666,\n",
       "  (3, 20) -> (1, 30) --- Cost: 196900.8736099447 --- Speed: 12.893583513318934,\n",
       "  (1, 30) -> (2, 41) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (2, 41) -> (5, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 5: [(0, 0) -> (1, 3) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 3) -> (1, 4) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 4) -> (1, 5) --- Cost: 50 --- Speed: 0,\n",
       "  (1, 5) -> (3, 16) --- Cost: 162736.67240491294 --- Speed: 11.721439557562666,\n",
       "  (3, 16) -> (2, 17) --- Cost: 4362.161149557014 --- Speed: 8,\n",
       "  (2, 17) -> (1, 28) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (1, 28) -> (3, 38) --- Cost: 196900.8736099447 --- Speed: 12.893583513318934,\n",
       "  (3, 38) -> (5, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 6: [(0, 0) -> (2, 2) --- Cost: 50 --- Speed: 0,\n",
       "  (2, 2) -> (2, 3) --- Cost: 50 --- Speed: 0,\n",
       "  (2, 3) -> (1, 14) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (1, 14) -> (2, 25) --- Cost: 168064.4915771227 --- Speed: 11.848022612736434,\n",
       "  (2, 25) -> (1, 37) --- Cost: 141228.8436168878 --- Speed: 10.860687395008398,\n",
       "  (1, 37) -> (5, 46) --- Cost: 0 --- Speed: 0],\n",
       " Vessel 7: [(0, 0) -> (3, 5) --- Cost: 50 --- Speed: 0,\n",
       "  (3, 5) -> (1, 17) --- Cost: 136751.9955624616 --- Speed: 10.744652927765777,\n",
       "  (1, 17) -> (3, 29) --- Cost: 136751.9955624616 --- Speed: 10.744652927765777,\n",
       "  (3, 29) -> (1, 42) --- Cost: 116529.80686978974 --- Speed: 9.918141164091487,\n",
       "  (1, 42) -> (5, 46) --- Cost: 0 --- Speed: 0]}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vessel_routes_incl_wa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Vessel 3: [1, 2, 1, 2, 5],\n",
       " Vessel 4: [1, 3, 1, 2, 5],\n",
       " Vessel 5: [1, 3, 2, 1, 3, 5],\n",
       " Vessel 6: [2, 1, 2, 1, 5],\n",
       " Vessel 7: [3, 1, 3, 1, 5]}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For each vessel, save the route, but only the port-sequence\n",
    "vessel_routes_seq = {}\n",
    "for vessel in vessels:\n",
    "    vessel_routes_seq[vessel] = []\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        if arc in waiting_arcs[vessel]:\n",
    "            continue\n",
    "        if x[arc.tuple, vessel].x > 0:\n",
    "            vessel_routes_seq[vessel].append(arc.destination_node.port.number)\n",
    "vessel_routes_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_solution_for_vessel(vessel, vessel_arcs):\n",
    "    # Create a directed graph\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # Add nodes to the graph\n",
    "    for node in NODES:\n",
    "        G.add_node(str(node.tuple))\n",
    "\n",
    "    # Add edges (arcs) to the graph\n",
    "    for arc in vessel_arcs[vessel]:\n",
    "        G.add_edge(str(arc.origin_node.tuple), str(arc.destination_node.tuple))\n",
    "\n",
    "    # Determine nodes with incoming and outgoing arcs\n",
    "    nodes_with_incoming_arcs = [node for node, degree in G.in_degree() if degree > 0]\n",
    "    nodes_with_outgoing_arcs = [node for node, degree in G.out_degree() if degree > 0]\n",
    "\n",
    "   # Create a list to hold node colors\n",
    "    node_colors = []\n",
    "    for node_str in G.nodes():\n",
    "        port_number, time = eval(node_str)  # Extract port number and time from the node label\n",
    "        q_value = q.get((port_number, time, vessel))  # Use .get() to safely access the dictionary\n",
    "        if q_value and q_value.x > 0 + EBS:\n",
    "            node_colors.append('brown')  # Color for nodes with non-zero q values\n",
    "        elif node_str in nodes_with_incoming_arcs or node_str in nodes_with_outgoing_arcs:\n",
    "            node_colors.append('green')  # Color for nodes with arcs\n",
    "        \n",
    "        else:\n",
    "            node_colors.append('skyblue')  # Default color for nodes without arcs or q values\n",
    "\n",
    "\n",
    "    # Resetting the y_offset and y_spacing\n",
    "    y_offset = 10\n",
    "    y_spacing = -30  # Increase vertical spacing for better clarity\n",
    "\n",
    "    # Manually specify the positions for each node\n",
    "    pos = {}\n",
    "    for node_str in G.nodes():\n",
    "        port_number, time = eval(node_str)  # Extract port number and time from the node label\n",
    "        # The x-coordinate is based on time, the y-coordinate is fixed for nodes with the same port\n",
    "        pos[node_str] = (time * 10, port_number * y_spacing)  # Multiplying time by 10 for better horizontal spacing\n",
    "\n",
    "    # Drawing the graph using the adjusted positions\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color=node_colors, font_size=10)\n",
    "    labels = nx.get_edge_attributes(G, 'weight')\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=labels)\n",
    "    plt.title(f\"Nodes and Arcs Graph for {vessel}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o[1,1,Vessel 3,1] 1.0\n",
      "o[1,23,Vessel 3,2] 1.0\n",
      "o[2,12,Vessel 3,1] 1.0\n",
      "o[2,33,Vessel 3,2] 1.0\n",
      "o[1,9,Vessel 4,1] 1.0\n",
      "o[1,30,Vessel 4,2] 1.0\n",
      "o[2,41,Vessel 4,1] 1.0\n",
      "o[3,20,Vessel 4,1] 1.0\n",
      "o[1,5,Vessel 5,1] 1.0\n",
      "o[1,28,Vessel 5,2] 1.0\n",
      "o[2,17,Vessel 5,1] 1.0\n",
      "o[3,16,Vessel 5,1] 1.0\n",
      "o[3,38,Vessel 5,2] 1.0\n",
      "o[1,14,Vessel 6,1] 1.0\n",
      "o[1,37,Vessel 6,2] 1.0\n",
      "o[2,3,Vessel 6,1] 1.0\n",
      "o[2,25,Vessel 6,2] 1.0\n",
      "o[1,17,Vessel 7,1] 1.0\n",
      "o[1,42,Vessel 7,2] 1.0\n",
      "o[3,5,Vessel 7,1] 1.0\n",
      "o[3,29,Vessel 7,2] 1.0\n"
     ]
    }
   ],
   "source": [
    "# Print the o vars\n",
    "for index in all_o_indices:\n",
    "    if o[index].x > 0:\n",
    "        print(o[index].varName, o[index].x)\n",
    "# for v in vessels:\n",
    "#     for node in regularNodes:\n",
    "#         for numvisits in range(1, MAX_VISITS[v] + 1):\n",
    "#             if o[node.port.number, node.time, v, numvisits].x > 0:\n",
    "#                 print(o[node.port.number, node.time, v, numvisits].varName, o[node.port.number, node.time, v, numvisits].x)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_solution_for_vessel(v, vessel_routes_incl_wa)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for v in vessels:\n",
    "#     visualize_network_for_vessel(v, vessel_arcs, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all x-vars that are 1\n",
    "active_arcs = {}\n",
    "for v in vessels:\n",
    "    v_arcs_active = []\n",
    "    for arc in vessel_arcs[v]:\n",
    "        if x[arc.tuple, v].x > 0 + EBS:\n",
    "            v_arcs_active.append(arc)\n",
    "    active_arcs[v] = v_arcs_active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(filepath):\n",
    "    # Open a file to write the results\n",
    "    with open(filepath, 'w') as file:\n",
    "        \n",
    "        file.write(\"Hyperparameters:\\n\")\n",
    "        file.write(f\"Number of Time Periods: {NUM_TIME_PERIODS}\\n\")\n",
    "        file.write(f\"Time Period Range: {TIME_PERIOD_RANGE}\\n\")\n",
    "        file.write(f\"Original Number of Vessels: {ORIGINAL_NUM_VESSELS}\\n\")\n",
    "        file.write(f\"Number of Vessels: {NUM_VESSELS}\\n\")\n",
    "        file.write(f\"Max Speed: {MAX_SPEED}\\n\")\n",
    "        file.write(f\"Min Speed: {MIN_SPEED}\\n\")\n",
    "        file.write(f\"Operating Speed: {OPERATING_SPEED}\\n\")\n",
    "        file.write(f\"Operating Cost: {OPERATING_COST}\\n\")\n",
    "        file.write(f\"Waiting Cost: {WAITING_COST}\\n\")\n",
    "        file.write(f\"Fuel Price (USD/ton): {FUEL_PRICE}\\n\\n\")\n",
    "        file.write(f\"Number of ports: {NUM_PORTS}\\n\\n\")\n",
    "        \n",
    "        file.write(\"\\nPorts:\\n\")\n",
    "        for port in ports:\n",
    "            file.write(f\"{port.__repr2__()}\\n\")\n",
    "            \n",
    "        file.write(\"\\nVessels:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel.__repr2__()}\\n\")\n",
    "        \n",
    "        file.write(\"\\nFull distance matrix:\\n\")\n",
    "        for row in FULL_DISTANCE_MATRIX:\n",
    "            row_str = ', '.join([f\"{item:.4f}\" for item in row])  # Format each item in the row\n",
    "            file.write(f\"[{row_str}]\\n\")\n",
    "            \n",
    "        file.write(\"\\n Start times:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel}: {start_times[vessel]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        file.write(\"----------------------------------------\\n\")\n",
    "        # Write the objective value\n",
    "        file.write(f\"Objective Value: {m.objVal}\\n\")    \n",
    "        file.write(\"----------------------------------------\\n\")\n",
    "        \n",
    "        # Log the GAP\n",
    "        file.write(\"\\nOptimality Gap:\\n\")\n",
    "        gap_percentage = m.MIPGap * 100  # Convert to percentage\n",
    "        file.write(f\"Current GAP: {gap_percentage:.2f}%\\n\")\n",
    "        \n",
    "        file.write(\"\\nVessel Routes:\\n\")\n",
    "        for vessel, route in vessel_routes_seq.items():\n",
    "            file.write(f\"{vessel}: {route}\\n\")\n",
    "            \n",
    "        # Write the active arcs to file\n",
    "        file.write(\"\\nActive Arcs:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel}: {[arc for arc in active_arcs[vessel]]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "        \n",
    "        # Write the all arcs to file\n",
    "        file.write(\"\\nAll Arcs:\\n\")\n",
    "        for vessel in vessels:\n",
    "            file.write(f\"{vessel}: {[arc for arc in vessel_arcs[vessel]]}\\n\")\n",
    "        file.write(\"\\n\")\n",
    "\n",
    "        # Write the values of all variables\n",
    "        file.write(\"Variable Values:\\n\")\n",
    "        for var in m.getVars():\n",
    "            file.write(f\"{var.varName}: {var.x}\\n\")\n",
    "            \n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG:\n",
    "    log(FILEPATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'new_official_solutions/LR1_1_DR1_3_VC1_V7a/MIRP_RF_SPEED_OPTI_results_LR1_1_DR1_3_VC1_V7a_45_NA.txt'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FILEPATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
